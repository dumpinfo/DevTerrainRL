<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - code analysis - DeepTerrainRL-1.1.1/learning/NeuralNet.cpp</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">DeepTerrainRL-1.1.1/learning</a> - NeuralNet.cpp<span style="font-size: 80%;"> (source / <a href="NeuralNet.cpp.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">code analysis</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">24</td>
            <td class="headerCovTableEntry">675</td>
            <td class="headerCovTableEntryLo">3.6 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2020-06-13 04:47:02</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">6</td>
            <td class="headerCovTableEntry">81</td>
            <td class="headerCovTableEntryLo">7.4 %</td>
          </tr>
          <tr>
            <td class="headerItem">Legend:</td>
            <td class="headerValueLeg">            Lines:
            <span class="coverLegendCov">hit</span>
            <span class="coverLegendNoCov">not hit</span>
</td>
            <td></td>
          </tr>
          <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : #include &quot;NeuralNet.h&quot;</a>
<span class="lineNum">       2 </span>            : #include &lt;caffe/util/hdf5.hpp&gt;
<span class="lineNum">       3 </span>            : #include &lt;json/json.h&gt;
<span class="lineNum">       4 </span>            : 
<span class="lineNum">       5 </span>            : #include &quot;util/Util.h&quot;
<span class="lineNum">       6 </span>            : #include &quot;util/FileUtil.h&quot;
<span class="lineNum">       7 </span>            : #include &quot;util/JsonUtil.h&quot;
<span class="lineNum">       8 </span>            : #include &quot;NNSolver.h&quot;
<span class="lineNum">       9 </span>            : #include &quot;AsyncSolver.h&quot;
<span class="lineNum">      10 </span>            : 
<span class="lineNum">      11 </span><span class="lineCov">          1 : const std::string gInputOffsetKey = &quot;InputOffset&quot;;</span>
<span class="lineNum">      12 </span><span class="lineCov">          1 : const std::string gInputScaleKey = &quot;InputScale&quot;;</span>
<span class="lineNum">      13 </span><span class="lineCov">          1 : const std::string gOutputOffsetKey = &quot;OutputOffset&quot;;</span>
<span class="lineNum">      14 </span><span class="lineCov">          1 : const std::string gOutputScaleKey = &quot;OutputScale&quot;;</span>
<span class="lineNum">      15 </span><span class="lineCov">          1 : const std::string gInputLayerName = &quot;data&quot;;</span>
<span class="lineNum">      16 </span><span class="lineCov">          1 : const std::string gOutputLayerName = &quot;output&quot;;</span>
<span class="lineNum">      17 </span>            : 
<a name="18"><span class="lineNum">      18 </span>            : std::mutex cNeuralNet::gOutputLock;</a>
<span class="lineNum">      19 </span>            : 
<span class="lineNum">      20 </span><span class="lineNoCov">          0 : cNeuralNet::tProblem::tProblem()</span>
<span class="lineNum">      21 </span>            : {
<span class="lineNum">      22 </span><span class="lineNoCov">          0 :         mX.resize(0, 0);</span>
<span class="lineNum">      23 </span><span class="lineNoCov">          0 :         mY.resize(0, 0);</span>
<span class="lineNum">      24 </span><span class="lineNoCov">          0 :         mPassesPerStep = 100;</span>
<a name="25"><span class="lineNum">      25 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">      26 </span>            : 
<span class="lineNum">      27 </span><span class="lineNoCov">          0 : bool cNeuralNet::tProblem::HasData() const</span>
<span class="lineNum">      28 </span>            : {
<span class="lineNum">      29 </span><span class="lineNoCov">          0 :         return mX.size() &gt; 0;</span>
<span class="lineNum">      30 </span>            : }
<span class="lineNum">      31 </span>            : 
<span class="lineNum">      32 </span>            : 
<span class="lineNum">      33 </span>            : 
<span class="lineNum">      34 </span>            : template &lt;typename Dtype&gt;
<span class="lineNum">      35 </span>            : caffe::Solver&lt;Dtype&gt;* GetSolver2(const caffe::SolverParameter&amp; param) {
<span class="lineNum">      36 </span>            :         caffe::SolverParameter_SolverType type = param.solver_type();
<span class="lineNum">      37 </span>            : 
<span class="lineNum">      38 </span>            :         switch (type) {
<span class="lineNum">      39 </span>            :         case caffe::SolverParameter_SolverType_SGD:
<span class="lineNum">      40 </span>            :                 return new caffe::SGDSolver&lt;Dtype&gt;(param);
<span class="lineNum">      41 </span>            :         case caffe::SolverParameter_SolverType_NESTEROV:
<span class="lineNum">      42 </span>            :                 return new caffe::NesterovSolver&lt;Dtype&gt;(param);
<span class="lineNum">      43 </span>            :         case caffe::SolverParameter_SolverType_ADAGRAD:
<span class="lineNum">      44 </span>            :                 return new caffe::AdaGradSolver&lt;Dtype&gt;(param);
<span class="lineNum">      45 </span>            :         default:
<span class="lineNum">      46 </span>            :                 LOG(FATAL) &lt;&lt; &quot;Unknown SolverType: &quot; &lt;&lt; type;
<span class="lineNum">      47 </span>            :         }
<span class="lineNum">      48 </span>            :         return (caffe::Solver&lt;Dtype&gt;*) NULL;
<span class="lineNum">      49 </span>            : }
<a name="50"><span class="lineNum">      50 </span>            : </a>
<span class="lineNum">      51 </span>            : 
<span class="lineNum">      52 </span><span class="lineCov">          2 : cNeuralNet::cNeuralNet()</span>
<span class="lineNum">      53 </span>            : {
<span class="lineNum">      54 </span><span class="lineCov">          2 :         Clear();</span>
<span class="lineNum">      55 </span><span class="lineCov">          2 :         mAsync = false;</span>
<a name="56"><span class="lineNum">      56 </span><span class="lineCov">          2 : }</span></a>
<span class="lineNum">      57 </span>            : 
<span class="lineNum">      58 </span><span class="lineCov">          2 : cNeuralNet::~cNeuralNet()</span>
<span class="lineNum">      59 </span>            : {
<a name="60"><span class="lineNum">      60 </span><span class="lineCov">          2 : }</span></a>
<span class="lineNum">      61 </span>            : 
<span class="lineNum">      62 </span><span class="lineNoCov">          0 : void cNeuralNet::LoadNet(const std::string&amp; net_file)</span>
<span class="lineNum">      63 </span>            : {
<span class="lineNum">      64 </span><span class="lineNoCov">          0 :         if (net_file != &quot;&quot;)</span>
<span class="lineNum">      65 </span>            :         {
<span class="lineNum">      66 </span><span class="lineNoCov">          0 :                 Clear();</span>
<span class="lineNum">      67 </span><span class="lineNoCov">          0 :                 mNet = std::unique_ptr&lt;cCaffeNetWrapper&gt;(new cCaffeNetWrapper(net_file, caffe::TEST));</span>
<span class="lineNum">      68 </span>            : 
<span class="lineNum">      69 </span><span class="lineNoCov">          0 :                 if (!ValidOffsetScale())</span>
<span class="lineNum">      70 </span>            :                 {
<span class="lineNum">      71 </span><span class="lineNoCov">          0 :                         InitOffsetScale();</span>
<span class="lineNum">      72 </span>            :                 }
<span class="lineNum">      73 </span>            : 
<span class="lineNum">      74 </span><span class="lineNoCov">          0 :                 if (HasSolver())</span>
<span class="lineNum">      75 </span>            :                 {
<span class="lineNum">      76 </span><span class="lineNoCov">          0 :                         SyncNetParams();</span>
<span class="lineNum">      77 </span>            :                 }
<span class="lineNum">      78 </span>            :         }
<a name="79"><span class="lineNum">      79 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">      80 </span>            : 
<span class="lineNum">      81 </span><span class="lineNoCov">          0 : void cNeuralNet::LoadModel(const std::string&amp; model_file)</span>
<span class="lineNum">      82 </span>            : {
<span class="lineNum">      83 </span><span class="lineNoCov">          0 :         if (model_file != &quot;&quot;)</span>
<span class="lineNum">      84 </span>            :         {
<span class="lineNum">      85 </span><span class="lineNoCov">          0 :                 if (HasNet())</span>
<span class="lineNum">      86 </span>            :                 {
<span class="lineNum">      87 </span><span class="lineNoCov">          0 :                         mNet-&gt;CopyTrainedLayersFromHDF5(model_file);</span>
<span class="lineNum">      88 </span><span class="lineNoCov">          0 :                         LoadScale(GetOffsetScaleFile(model_file));</span>
<span class="lineNum">      89 </span><span class="lineNoCov">          0 :                         SyncSolverParams();</span>
<span class="lineNum">      90 </span>            : 
<span class="lineNum">      91 </span><span class="lineNoCov">          0 :                         mValidModel = true;</span>
<span class="lineNum">      92 </span>            :                 }
<span class="lineNum">      93 </span><span class="lineNoCov">          0 :                 else if (HasSolver())</span>
<span class="lineNum">      94 </span>            :                 {
<span class="lineNum">      95 </span><span class="lineNoCov">          0 :                         auto net = GetTrainNet();</span>
<span class="lineNum">      96 </span><span class="lineNoCov">          0 :                         net-&gt;CopyTrainedLayersFromHDF5(model_file);</span>
<span class="lineNum">      97 </span><span class="lineNoCov">          0 :                         LoadScale(GetOffsetScaleFile(model_file));</span>
<span class="lineNum">      98 </span><span class="lineNoCov">          0 :                         SyncNetParams();</span>
<span class="lineNum">      99 </span>            : 
<span class="lineNum">     100 </span><span class="lineNoCov">          0 :                         mValidModel = true;</span>
<span class="lineNum">     101 </span>            :                 }
<span class="lineNum">     102 </span>            :                 else
<span class="lineNum">     103 </span>            :                 {
<span class="lineNum">     104 </span><span class="lineNoCov">          0 :                         printf(&quot;Net structure has not been initialized\n&quot;);</span>
<span class="lineNum">     105 </span><span class="lineNoCov">          0 :                         assert(false);</span>
<span class="lineNum">     106 </span>            :                 }
<span class="lineNum">     107 </span>            :         }
<a name="108"><span class="lineNum">     108 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     109 </span>            : 
<span class="lineNum">     110 </span><span class="lineNoCov">          0 : void cNeuralNet::LoadSolver(const std::string&amp; solver_file, bool async)</span>
<span class="lineNum">     111 </span>            : {
<span class="lineNum">     112 </span><span class="lineNoCov">          0 :         if (solver_file != &quot;&quot;)</span>
<span class="lineNum">     113 </span>            :         {
<span class="lineNum">     114 </span><span class="lineNoCov">          0 :                 mSolverFile = solver_file;</span>
<span class="lineNum">     115 </span><span class="lineNoCov">          0 :                 mAsync = async;</span>
<span class="lineNum">     116 </span>            : 
<span class="lineNum">     117 </span><span class="lineNoCov">          0 :                 if (mAsync)</span>
<span class="lineNum">     118 </span>            :                 {
<span class="lineNum">     119 </span><span class="lineNoCov">          0 :                         cNNSolver::BuildSolverAsync(solver_file, mSolver);</span>
<span class="lineNum">     120 </span>            :                 }
<span class="lineNum">     121 </span>            :                 else
<span class="lineNum">     122 </span>            :                 {
<span class="lineNum">     123 </span><span class="lineNoCov">          0 :                         cNNSolver::BuildSolver(solver_file, mSolver);</span>
<span class="lineNum">     124 </span>            :                 }
<span class="lineNum">     125 </span>            : 
<span class="lineNum">     126 </span><span class="lineNoCov">          0 :                 if (!ValidOffsetScale())</span>
<span class="lineNum">     127 </span>            :                 {
<span class="lineNum">     128 </span><span class="lineNoCov">          0 :                         InitOffsetScale();</span>
<span class="lineNum">     129 </span>            :                 }
<span class="lineNum">     130 </span>            : 
<span class="lineNum">     131 </span><span class="lineNoCov">          0 :                 if (HasNet())</span>
<span class="lineNum">     132 </span>            :                 {
<span class="lineNum">     133 </span><span class="lineNoCov">          0 :                         SyncSolverParams();</span>
<span class="lineNum">     134 </span>            :                 }
<span class="lineNum">     135 </span>            :         }
<a name="136"><span class="lineNum">     136 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     137 </span>            : 
<span class="lineNum">     138 </span><span class="lineNoCov">          0 : void cNeuralNet::LoadScale(const std::string&amp; scale_file)</span>
<span class="lineNum">     139 </span>            : {
<span class="lineNum">     140 </span><span class="lineNoCov">          0 :         std::ifstream f_stream(scale_file);</span>
<span class="lineNum">     141 </span><span class="lineNoCov">          0 :         Json::Reader reader;</span>
<span class="lineNum">     142 </span><span class="lineNoCov">          0 :         Json::Value root;</span>
<span class="lineNum">     143 </span><span class="lineNoCov">          0 :         bool succ = reader.parse(f_stream, root);</span>
<span class="lineNum">     144 </span><span class="lineNoCov">          0 :         f_stream.close();</span>
<span class="lineNum">     145 </span>            : 
<span class="lineNum">     146 </span><span class="lineNoCov">          0 :         int input_size = GetInputSize();</span>
<span class="lineNum">     147 </span><span class="lineNoCov">          0 :         if (succ &amp;&amp; !root[gInputOffsetKey].isNull())</span>
<span class="lineNum">     148 </span>            :         {
<span class="lineNum">     149 </span><span class="lineNoCov">          0 :                 Eigen::VectorXd offset;</span>
<span class="lineNum">     150 </span><span class="lineNoCov">          0 :                 succ &amp;= cJsonUtil::ReadVectorJson(root[gInputOffsetKey], offset);</span>
<span class="lineNum">     151 </span>            : 
<span class="lineNum">     152 </span><span class="lineNoCov">          0 :                 int offset_size = static_cast&lt;int&gt;(offset.size());</span>
<span class="lineNum">     153 </span><span class="lineNoCov">          0 :                 if (offset_size == input_size)</span>
<span class="lineNum">     154 </span>            :                 {
<span class="lineNum">     155 </span><span class="lineNoCov">          0 :                         mInputOffset = offset;</span>
<span class="lineNum">     156 </span>            :                 }
<span class="lineNum">     157 </span>            :                 else
<span class="lineNum">     158 </span>            :                 {
<span class="lineNum">     159 </span><span class="lineNoCov">          0 :                         printf(&quot;Invalid input offset size, expecting %i, but got %i\n&quot;, input_size, offset_size);</span>
<span class="lineNum">     160 </span><span class="lineNoCov">          0 :                         succ = false;</span>
<span class="lineNum">     161 </span>            :                 }
<span class="lineNum">     162 </span>            :         }
<span class="lineNum">     163 </span>            : 
<span class="lineNum">     164 </span><span class="lineNoCov">          0 :         if (succ &amp;&amp; !root[gInputScaleKey].isNull())</span>
<span class="lineNum">     165 </span>            :         {
<span class="lineNum">     166 </span><span class="lineNoCov">          0 :                 Eigen::VectorXd scale;</span>
<span class="lineNum">     167 </span><span class="lineNoCov">          0 :                 succ &amp;= cJsonUtil::ReadVectorJson(root[gInputScaleKey], scale);</span>
<span class="lineNum">     168 </span>            : 
<span class="lineNum">     169 </span><span class="lineNoCov">          0 :                 int scale_size = static_cast&lt;int&gt;(scale.size());</span>
<span class="lineNum">     170 </span><span class="lineNoCov">          0 :                 if (scale_size == input_size)</span>
<span class="lineNum">     171 </span>            :                 {
<span class="lineNum">     172 </span><span class="lineNoCov">          0 :                         mInputScale = scale;</span>
<span class="lineNum">     173 </span>            :                 }
<span class="lineNum">     174 </span>            :                 else
<span class="lineNum">     175 </span>            :                 {
<span class="lineNum">     176 </span><span class="lineNoCov">          0 :                         printf(&quot;Invalid input scale size, expecting %i, but got %i\n&quot;, input_size, scale_size);</span>
<span class="lineNum">     177 </span><span class="lineNoCov">          0 :                         succ = false;</span>
<span class="lineNum">     178 </span>            :                 }
<span class="lineNum">     179 </span>            :         }
<span class="lineNum">     180 </span>            : 
<span class="lineNum">     181 </span><span class="lineNoCov">          0 :         int output_size = GetOutputSize();</span>
<span class="lineNum">     182 </span><span class="lineNoCov">          0 :         if (succ &amp;&amp; !root[gOutputOffsetKey].isNull())</span>
<span class="lineNum">     183 </span>            :         {
<span class="lineNum">     184 </span><span class="lineNoCov">          0 :                 Eigen::VectorXd offset;</span>
<span class="lineNum">     185 </span><span class="lineNoCov">          0 :                 succ &amp;= cJsonUtil::ReadVectorJson(root[gOutputOffsetKey], offset);</span>
<span class="lineNum">     186 </span>            : 
<span class="lineNum">     187 </span><span class="lineNoCov">          0 :                 int offset_size = static_cast&lt;int&gt;(offset.size());</span>
<span class="lineNum">     188 </span><span class="lineNoCov">          0 :                 if (offset_size == output_size)</span>
<span class="lineNum">     189 </span>            :                 {
<span class="lineNum">     190 </span><span class="lineNoCov">          0 :                         mOutputOffset = offset;</span>
<span class="lineNum">     191 </span>            :                 }
<span class="lineNum">     192 </span>            :                 else
<span class="lineNum">     193 </span>            :                 {
<span class="lineNum">     194 </span><span class="lineNoCov">          0 :                         printf(&quot;Invalid output offset size, expecting %i, but got %i\n&quot;, output_size, offset_size);</span>
<span class="lineNum">     195 </span><span class="lineNoCov">          0 :                         succ = false;</span>
<span class="lineNum">     196 </span>            :                 }
<span class="lineNum">     197 </span>            :         }
<span class="lineNum">     198 </span>            : 
<span class="lineNum">     199 </span><span class="lineNoCov">          0 :         if (succ &amp;&amp; !root[gOutputScaleKey].isNull())</span>
<span class="lineNum">     200 </span>            :         {
<span class="lineNum">     201 </span><span class="lineNoCov">          0 :                 Eigen::VectorXd scale;</span>
<span class="lineNum">     202 </span><span class="lineNoCov">          0 :                 succ &amp;= cJsonUtil::ReadVectorJson(root[gOutputScaleKey], scale);</span>
<span class="lineNum">     203 </span>            : 
<span class="lineNum">     204 </span><span class="lineNoCov">          0 :                 int scale_size = static_cast&lt;int&gt;(scale.size());</span>
<span class="lineNum">     205 </span><span class="lineNoCov">          0 :                 if (scale_size == output_size)</span>
<span class="lineNum">     206 </span>            :                 {
<span class="lineNum">     207 </span><span class="lineNoCov">          0 :                         mOutputScale = scale;</span>
<span class="lineNum">     208 </span>            :                 }
<span class="lineNum">     209 </span>            :                 else
<span class="lineNum">     210 </span>            :                 {
<span class="lineNum">     211 </span><span class="lineNoCov">          0 :                         printf(&quot;Invalid output scale size, expecting %i, but got %i\n&quot;, output_size, scale_size);</span>
<span class="lineNum">     212 </span><span class="lineNoCov">          0 :                         succ = false;</span>
<span class="lineNum">     213 </span>            :                 }
<span class="lineNum">     214 </span>            :         }
<a name="215"><span class="lineNum">     215 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     216 </span>            : 
<span class="lineNum">     217 </span><span class="lineCov">          2 : void cNeuralNet::Clear()</span>
<span class="lineNum">     218 </span>            : {
<span class="lineNum">     219 </span><span class="lineCov">          2 :         mNet.reset();</span>
<span class="lineNum">     220 </span><span class="lineCov">          2 :         mSolver.reset();</span>
<span class="lineNum">     221 </span><span class="lineCov">          2 :         mValidModel = false;</span>
<span class="lineNum">     222 </span>            : 
<span class="lineNum">     223 </span><span class="lineCov">          2 :         mInputOffset.resize(0);</span>
<span class="lineNum">     224 </span><span class="lineCov">          2 :         mInputScale.resize(0);</span>
<span class="lineNum">     225 </span><span class="lineCov">          2 :         mOutputOffset.resize(0);</span>
<span class="lineNum">     226 </span><span class="lineCov">          2 :         mOutputScale.resize(0);</span>
<a name="227"><span class="lineNum">     227 </span><span class="lineCov">          2 : }</span></a>
<span class="lineNum">     228 </span>            : 
<span class="lineNum">     229 </span><span class="lineNoCov">          0 : void cNeuralNet::Train(const tProblem&amp; prob)</span>
<span class="lineNum">     230 </span>            : {
<span class="lineNum">     231 </span><span class="lineNoCov">          0 :         if (HasSolver())</span>
<span class="lineNum">     232 </span>            :         {
<span class="lineNum">     233 </span><span class="lineNoCov">          0 :                 LoadTrainData(prob.mX, prob.mY);</span>
<span class="lineNum">     234 </span>            : 
<span class="lineNum">     235 </span><span class="lineNoCov">          0 :                 int batch_size = GetBatchSize();</span>
<span class="lineNum">     236 </span><span class="lineNoCov">          0 :                 int num_batches = static_cast&lt;int&gt;(prob.mX.rows()) / batch_size;</span>
<span class="lineNum">     237 </span>            :                 
<span class="lineNum">     238 </span><span class="lineNoCov">          0 :                 StepSolver(prob.mPassesPerStep * num_batches);</span>
<span class="lineNum">     239 </span>            :         }
<span class="lineNum">     240 </span>            :         else
<span class="lineNum">     241 </span>            :         {
<span class="lineNum">     242 </span><span class="lineNoCov">          0 :                 printf(&quot;Solver has not been initialized\n&quot;);</span>
<span class="lineNum">     243 </span><span class="lineNoCov">          0 :                 assert(false);</span>
<span class="lineNum">     244 </span>            :         }
<a name="245"><span class="lineNum">     245 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     246 </span>            : 
<span class="lineNum">     247 </span><span class="lineNoCov">          0 : double cNeuralNet::ForwardBackward(const tProblem&amp; prob)</span>
<span class="lineNum">     248 </span>            : {
<span class="lineNum">     249 </span><span class="lineNoCov">          0 :         double loss = 0;</span>
<span class="lineNum">     250 </span><span class="lineNoCov">          0 :         if (HasSolver())</span>
<span class="lineNum">     251 </span>            :         {
<span class="lineNum">     252 </span><span class="lineNoCov">          0 :                 LoadTrainData(prob.mX, prob.mY);</span>
<span class="lineNum">     253 </span><span class="lineNoCov">          0 :                 loss = mSolver-&gt;ForwardBackward();</span>
<span class="lineNum">     254 </span>            :         }
<span class="lineNum">     255 </span>            :         else
<span class="lineNum">     256 </span>            :         {
<span class="lineNum">     257 </span><span class="lineNoCov">          0 :                 printf(&quot;Solver has not been initialized\n&quot;);</span>
<span class="lineNum">     258 </span><span class="lineNoCov">          0 :                 assert(false);</span>
<span class="lineNum">     259 </span>            :         }
<span class="lineNum">     260 </span><span class="lineNoCov">          0 :         return loss;</span>
<a name="261"><span class="lineNum">     261 </span>            : }</a>
<span class="lineNum">     262 </span>            : 
<span class="lineNum">     263 </span><span class="lineNoCov">          0 : void cNeuralNet::StepSolver(int iters)</span>
<span class="lineNum">     264 </span>            : {
<span class="lineNum">     265 </span><span class="lineNoCov">          0 :         mSolver-&gt;ApplySteps(iters);</span>
<span class="lineNum">     266 </span>            : 
<span class="lineNum">     267 </span><span class="lineNoCov">          0 :         if (HasNet())</span>
<span class="lineNum">     268 </span>            :         {
<span class="lineNum">     269 </span><span class="lineNoCov">          0 :                 SyncNetParams();</span>
<span class="lineNum">     270 </span>            :         }
<span class="lineNum">     271 </span><span class="lineNoCov">          0 :         mValidModel = true;</span>
<a name="272"><span class="lineNum">     272 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     273 </span>            : 
<span class="lineNum">     274 </span><span class="lineNoCov">          0 : void cNeuralNet::ResetSolver()</span>
<span class="lineNum">     275 </span>            : {
<span class="lineNum">     276 </span><span class="lineNoCov">          0 :         mSolver.reset();</span>
<span class="lineNum">     277 </span><span class="lineNoCov">          0 :         LoadSolver(mSolverFile, mAsync);</span>
<a name="278"><span class="lineNum">     278 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     279 </span>            : 
<span class="lineNum">     280 </span><span class="lineNoCov">          0 : void cNeuralNet::CalcOffsetScale(const Eigen::MatrixXd&amp; X, Eigen::VectorXd&amp; out_offset, Eigen::VectorXd&amp; out_scale) const</span>
<span class="lineNum">     281 </span>            : {
<span class="lineNum">     282 </span><span class="lineNoCov">          0 :         int num_pts = static_cast&lt;int&gt;(X.rows());</span>
<span class="lineNum">     283 </span><span class="lineNoCov">          0 :         assert(num_pts &gt; 1);</span>
<span class="lineNum">     284 </span>            : 
<span class="lineNum">     285 </span><span class="lineNoCov">          0 :         double norm = 1.0 / num_pts;</span>
<span class="lineNum">     286 </span>            : 
<span class="lineNum">     287 </span><span class="lineNoCov">          0 :         const int input_size = GetInputSize();</span>
<span class="lineNum">     288 </span><span class="lineNoCov">          0 :         out_offset = Eigen::VectorXd::Zero(input_size);</span>
<span class="lineNum">     289 </span><span class="lineNoCov">          0 :         out_scale = Eigen::VectorXd::Zero(input_size);</span>
<span class="lineNum">     290 </span>            : 
<span class="lineNum">     291 </span><span class="lineNoCov">          0 :         for (int i = 0; i &lt; num_pts; ++i)</span>
<span class="lineNum">     292 </span>            :         {
<span class="lineNum">     293 </span><span class="lineNoCov">          0 :                 out_offset += norm * X.row(i);</span>
<span class="lineNum">     294 </span>            :         }
<span class="lineNum">     295 </span>            : 
<span class="lineNum">     296 </span><span class="lineNoCov">          0 :         Eigen::VectorXd curr_x = Eigen::VectorXd::Zero(num_pts);</span>
<span class="lineNum">     297 </span><span class="lineNoCov">          0 :         for (int i = 0; i &lt; num_pts; ++i)</span>
<span class="lineNum">     298 </span>            :         {
<span class="lineNum">     299 </span><span class="lineNoCov">          0 :                 curr_x = X.row(i);</span>
<span class="lineNum">     300 </span><span class="lineNoCov">          0 :                 curr_x -= out_offset;</span>
<span class="lineNum">     301 </span><span class="lineNoCov">          0 :                 out_scale += norm * curr_x.cwiseProduct(curr_x);</span>
<span class="lineNum">     302 </span>            :         }
<span class="lineNum">     303 </span>            : 
<span class="lineNum">     304 </span><span class="lineNoCov">          0 :         out_offset = -out_offset;</span>
<span class="lineNum">     305 </span>            : 
<span class="lineNum">     306 </span><span class="lineNoCov">          0 :         out_scale = out_scale.cwiseSqrt();</span>
<span class="lineNum">     307 </span><span class="lineNoCov">          0 :         for (int i = 0; i &lt; out_scale.size(); ++i)</span>
<span class="lineNum">     308 </span>            :         {
<span class="lineNum">     309 </span><span class="lineNoCov">          0 :                 double val = out_scale[i];</span>
<span class="lineNum">     310 </span><span class="lineNoCov">          0 :                 val = (val == 0) ? 0 : (1 / val);</span>
<span class="lineNum">     311 </span><span class="lineNoCov">          0 :                 out_scale[i] = val;</span>
<span class="lineNum">     312 </span>            :         }
<a name="313"><span class="lineNum">     313 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     314 </span>            : 
<span class="lineNum">     315 </span><span class="lineNoCov">          0 : void cNeuralNet::SetInputOffsetScale(const Eigen::VectorXd&amp; offset, const Eigen::VectorXd&amp; scale)</span>
<span class="lineNum">     316 </span>            : {
<span class="lineNum">     317 </span><span class="lineNoCov">          0 :         assert(offset.size() == GetInputSize());</span>
<span class="lineNum">     318 </span><span class="lineNoCov">          0 :         assert(scale.size() == GetInputSize());</span>
<span class="lineNum">     319 </span><span class="lineNoCov">          0 :         mInputOffset = offset;</span>
<span class="lineNum">     320 </span><span class="lineNoCov">          0 :         mInputScale = scale;</span>
<a name="321"><span class="lineNum">     321 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     322 </span>            : 
<span class="lineNum">     323 </span><span class="lineNoCov">          0 : void cNeuralNet::SetOutputOffsetScale(const Eigen::VectorXd&amp; offset, const Eigen::VectorXd&amp; scale)</span>
<span class="lineNum">     324 </span>            : {
<span class="lineNum">     325 </span><span class="lineNoCov">          0 :         assert(offset.size() == GetOutputSize());</span>
<span class="lineNum">     326 </span><span class="lineNoCov">          0 :         assert(scale.size() == GetOutputSize());</span>
<span class="lineNum">     327 </span><span class="lineNoCov">          0 :         mOutputOffset = offset;</span>
<span class="lineNum">     328 </span><span class="lineNoCov">          0 :         mOutputScale = scale;</span>
<a name="329"><span class="lineNum">     329 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     330 </span>            : 
<span class="lineNum">     331 </span><span class="lineNoCov">          0 : const Eigen::VectorXd&amp; cNeuralNet::GetInputOffset() const</span>
<span class="lineNum">     332 </span>            : {
<span class="lineNum">     333 </span><span class="lineNoCov">          0 :         return mInputOffset;</span>
<a name="334"><span class="lineNum">     334 </span>            : }</a>
<span class="lineNum">     335 </span>            : 
<span class="lineNum">     336 </span><span class="lineNoCov">          0 : const Eigen::VectorXd&amp; cNeuralNet::GetInputScale() const</span>
<span class="lineNum">     337 </span>            : {
<span class="lineNum">     338 </span><span class="lineNoCov">          0 :         return mInputScale;</span>
<a name="339"><span class="lineNum">     339 </span>            : }</a>
<span class="lineNum">     340 </span>            : 
<span class="lineNum">     341 </span><span class="lineNoCov">          0 : const Eigen::VectorXd&amp; cNeuralNet::GetOutputOffset() const</span>
<span class="lineNum">     342 </span>            : {
<span class="lineNum">     343 </span><span class="lineNoCov">          0 :         return mOutputOffset;</span>
<a name="344"><span class="lineNum">     344 </span>            : }</a>
<span class="lineNum">     345 </span>            : 
<span class="lineNum">     346 </span><span class="lineNoCov">          0 : const Eigen::VectorXd&amp; cNeuralNet::GetOutputScale() const</span>
<span class="lineNum">     347 </span>            : {
<span class="lineNum">     348 </span><span class="lineNoCov">          0 :         return mOutputScale;</span>
<span class="lineNum">     349 </span>            : }
<a name="350"><span class="lineNum">     350 </span>            : </a>
<span class="lineNum">     351 </span>            : 
<span class="lineNum">     352 </span><span class="lineNoCov">          0 : void cNeuralNet::Eval(const Eigen::VectorXd&amp; x, Eigen::VectorXd&amp; out_y) const</span>
<span class="lineNum">     353 </span>            : {
<span class="lineNum">     354 </span><span class="lineNoCov">          0 :         const int input_size = GetInputSize();</span>
<span class="lineNum">     355 </span><span class="lineNoCov">          0 :         assert(HasNet());</span>
<span class="lineNum">     356 </span><span class="lineNoCov">          0 :         assert(x.size() == input_size);</span>
<span class="lineNum">     357 </span>            : 
<span class="lineNum">     358 </span><span class="lineNoCov">          0 :         caffe::Blob&lt;tNNData&gt; blob(1, 1, 1, input_size);</span>
<span class="lineNum">     359 </span><span class="lineNoCov">          0 :         tNNData* blob_data = blob.mutable_cpu_data();</span>
<span class="lineNum">     360 </span>            :         
<span class="lineNum">     361 </span><span class="lineNoCov">          0 :         Eigen::VectorXd norm_x = x;</span>
<span class="lineNum">     362 </span><span class="lineNoCov">          0 :         NormalizeInput(norm_x);</span>
<span class="lineNum">     363 </span>            : 
<span class="lineNum">     364 </span><span class="lineNoCov">          0 :         for (int i = 0; i &lt; blob.count(); ++i)</span>
<span class="lineNum">     365 </span>            :         {
<span class="lineNum">     366 </span><span class="lineNoCov">          0 :                 blob_data[i] = norm_x[i];</span>
<span class="lineNum">     367 </span>            :         }
<span class="lineNum">     368 </span>            : 
<span class="lineNum">     369 </span><span class="lineNoCov">          0 :         tNNData loss = 0;</span>
<span class="lineNum">     370 </span><span class="lineNoCov">          0 :         const std::vector&lt;caffe::Blob&lt;tNNData&gt;*&gt;&amp; input_blobs = mNet-&gt;input_blobs();</span>
<span class="lineNum">     371 </span><span class="lineNoCov">          0 :         input_blobs[0]-&gt;CopyFrom(blob);</span>
<span class="lineNum">     372 </span><span class="lineNoCov">          0 :         const std::vector&lt;caffe::Blob&lt;tNNData&gt;*&gt;&amp; result_arr = mNet-&gt;Forward();</span>
<span class="lineNum">     373 </span>            : 
<span class="lineNum">     374 </span><span class="lineNoCov">          0 :         FetchOutput(result_arr, out_y);</span>
<a name="375"><span class="lineNum">     375 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     376 </span>            : 
<span class="lineNum">     377 </span><span class="lineNoCov">          0 : void cNeuralNet::EvalBatch(const Eigen::MatrixXd&amp; X, Eigen::MatrixXd&amp; out_Y) const</span>
<span class="lineNum">     378 </span>            : {
<span class="lineNum">     379 </span><span class="lineNoCov">          0 :         if (HasSolver() &amp;&amp; GetBatchSize() &gt; 1)</span>
<span class="lineNum">     380 </span>            :         {
<span class="lineNum">     381 </span><span class="lineNoCov">          0 :                 EvalBatchSolver(X, out_Y);</span>
<span class="lineNum">     382 </span>            :         }
<span class="lineNum">     383 </span>            :         else
<span class="lineNum">     384 </span>            :         {
<span class="lineNum">     385 </span><span class="lineNoCov">          0 :                 EvalBatchNet(X, out_Y);</span>
<span class="lineNum">     386 </span>            :         }
<a name="387"><span class="lineNum">     387 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     388 </span>            : 
<span class="lineNum">     389 </span><span class="lineNoCov">          0 : void cNeuralNet::Backward(const Eigen::VectorXd&amp; y_diff, Eigen::VectorXd&amp; out_x_diff) const</span>
<span class="lineNum">     390 </span>            : {
<span class="lineNum">     391 </span><span class="lineNoCov">          0 :         assert(HasNet());</span>
<span class="lineNum">     392 </span><span class="lineNoCov">          0 :         int output_size = GetOutputSize();</span>
<span class="lineNum">     393 </span><span class="lineNoCov">          0 :         const auto&amp; top_vec = mNet-&gt;top_vecs();</span>
<span class="lineNum">     394 </span><span class="lineNoCov">          0 :         const auto&amp; top_blob = top_vec[top_vec.size() - 1][0];</span>
<span class="lineNum">     395 </span><span class="lineNoCov">          0 :         assert(y_diff.size() == output_size);</span>
<span class="lineNum">     396 </span><span class="lineNoCov">          0 :         assert(y_diff.size() == top_blob-&gt;count());</span>
<span class="lineNum">     397 </span><span class="lineNoCov">          0 :         auto top_data = top_blob-&gt;mutable_cpu_diff();</span>
<span class="lineNum">     398 </span>            : 
<span class="lineNum">     399 </span>            :         // normalization is weird but the math seems to work out this way
<span class="lineNum">     400 </span><span class="lineNoCov">          0 :         Eigen::VectorXd norm_y_diff = y_diff;</span>
<span class="lineNum">     401 </span><span class="lineNoCov">          0 :         UnnormalizeOutputDiff(norm_y_diff);</span>
<span class="lineNum">     402 </span>            : 
<span class="lineNum">     403 </span><span class="lineNoCov">          0 :         for (int i = 0; i &lt; output_size; ++i)</span>
<span class="lineNum">     404 </span>            :         {
<span class="lineNum">     405 </span><span class="lineNoCov">          0 :                 top_data[i] = norm_y_diff[i];</span>
<span class="lineNum">     406 </span>            :         }
<span class="lineNum">     407 </span>            : 
<span class="lineNum">     408 </span><span class="lineNoCov">          0 :         mNet-&gt;ClearParamDiffs();</span>
<span class="lineNum">     409 </span><span class="lineNoCov">          0 :         mNet-&gt;Backward();</span>
<span class="lineNum">     410 </span>            : 
<span class="lineNum">     411 </span><span class="lineNoCov">          0 :         auto bottom_vecs = mNet-&gt;bottom_vecs();</span>
<span class="lineNum">     412 </span><span class="lineNoCov">          0 :         const auto&amp; bottom_blob = bottom_vecs[0][0];</span>
<span class="lineNum">     413 </span><span class="lineNoCov">          0 :         const tNNData* bottom_data = bottom_blob-&gt;cpu_diff();</span>
<span class="lineNum">     414 </span>            : 
<span class="lineNum">     415 </span><span class="lineNoCov">          0 :         int input_size = GetInputSize();</span>
<span class="lineNum">     416 </span><span class="lineNoCov">          0 :         assert(bottom_blob-&gt;count() == input_size);</span>
<span class="lineNum">     417 </span><span class="lineNoCov">          0 :         out_x_diff.resize(input_size);</span>
<span class="lineNum">     418 </span>            : 
<span class="lineNum">     419 </span><span class="lineNoCov">          0 :         for (int i = 0; i &lt; input_size; ++i)</span>
<span class="lineNum">     420 </span>            :         {
<span class="lineNum">     421 </span><span class="lineNoCov">          0 :                 out_x_diff[i] = bottom_data[i];</span>
<span class="lineNum">     422 </span>            :         }
<span class="lineNum">     423 </span>            :         
<span class="lineNum">     424 </span><span class="lineNoCov">          0 :         NormalizeInputDiff(out_x_diff);</span>
<a name="425"><span class="lineNum">     425 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     426 </span>            : 
<span class="lineNum">     427 </span><span class="lineNoCov">          0 : void cNeuralNet::EvalBatchNet(const Eigen::MatrixXd&amp; X, Eigen::MatrixXd&amp; out_Y) const</span>
<span class="lineNum">     428 </span>            : {
<span class="lineNum">     429 </span><span class="lineNoCov">          0 :         assert(HasNet());</span>
<span class="lineNum">     430 </span><span class="lineNoCov">          0 :         int num_data = static_cast&lt;int&gt;(X.rows());</span>
<span class="lineNum">     431 </span><span class="lineNoCov">          0 :         Eigen::VectorXd x;</span>
<span class="lineNum">     432 </span><span class="lineNoCov">          0 :         Eigen::VectorXd y;</span>
<span class="lineNum">     433 </span>            : 
<span class="lineNum">     434 </span><span class="lineNoCov">          0 :         out_Y.resize(num_data, GetOutputSize());</span>
<span class="lineNum">     435 </span><span class="lineNoCov">          0 :         for (int i = 0; i &lt; num_data; ++i)</span>
<span class="lineNum">     436 </span>            :         {
<span class="lineNum">     437 </span><span class="lineNoCov">          0 :                 x = X.row(i);</span>
<span class="lineNum">     438 </span><span class="lineNoCov">          0 :                 Eval(x, y);</span>
<span class="lineNum">     439 </span><span class="lineNoCov">          0 :                 out_Y.row(i) = y;</span>
<span class="lineNum">     440 </span>            :         }
<a name="441"><span class="lineNum">     441 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     442 </span>            : 
<span class="lineNum">     443 </span><span class="lineNoCov">          0 : void cNeuralNet::EvalBatchSolver(const Eigen::MatrixXd&amp; X, Eigen::MatrixXd&amp; out_Y) const</span>
<span class="lineNum">     444 </span>            : {
<span class="lineNum">     445 </span><span class="lineNoCov">          0 :         assert(HasSolver());</span>
<span class="lineNum">     446 </span><span class="lineNoCov">          0 :         boost::shared_ptr&lt;caffe::Net&lt;cNeuralNet::tNNData&gt;&gt; net = GetTrainNet();</span>
<span class="lineNum">     447 </span>            : 
<span class="lineNum">     448 </span><span class="lineNoCov">          0 :         const int num_inputs = static_cast&lt;int&gt;(X.rows());</span>
<span class="lineNum">     449 </span><span class="lineNoCov">          0 :         const int input_size = GetInputSize();</span>
<span class="lineNum">     450 </span><span class="lineNoCov">          0 :         const int output_size = GetOutputSize();</span>
<span class="lineNum">     451 </span><span class="lineNoCov">          0 :         assert(X.cols() == input_size);</span>
<span class="lineNum">     452 </span>            : 
<span class="lineNum">     453 </span><span class="lineNoCov">          0 :         int batch_size = GetBatchSize();</span>
<span class="lineNum">     454 </span><span class="lineNoCov">          0 :         int num_data = static_cast&lt;int&gt;(X.rows());</span>
<span class="lineNum">     455 </span><span class="lineNoCov">          0 :         int num_batches = static_cast&lt;int&gt;(std::ceil((1.0 * X.rows()) / batch_size));</span>
<span class="lineNum">     456 </span><span class="lineNoCov">          0 :         out_Y.resize(num_data, output_size);</span>
<span class="lineNum">     457 </span>            : 
<span class="lineNum">     458 </span><span class="lineNoCov">          0 :         std::vector&lt;tNNData&gt; data(batch_size * input_size);</span>
<span class="lineNum">     459 </span>            : 
<span class="lineNum">     460 </span><span class="lineNoCov">          0 :         auto data_layer = boost::static_pointer_cast&lt;caffe::MemoryDataLayer&lt;tNNData&gt;&gt;(net-&gt;layer_by_name(GetInputLayerName()));</span>
<span class="lineNum">     461 </span>            :         
<span class="lineNum">     462 </span><span class="lineNoCov">          0 :         for (int b = 0; b &lt; num_batches; ++b)</span>
<span class="lineNum">     463 </span>            :         {
<span class="lineNum">     464 </span><span class="lineNoCov">          0 :                 for (int i = 0; i &lt; batch_size; ++i)</span>
<span class="lineNum">     465 </span>            :                 {
<span class="lineNum">     466 </span><span class="lineNoCov">          0 :                         int data_idx = b * batch_size + i;</span>
<span class="lineNum">     467 </span><span class="lineNoCov">          0 :                         if (data_idx &gt;= num_data)</span>
<span class="lineNum">     468 </span>            :                         {
<span class="lineNum">     469 </span><span class="lineNoCov">          0 :                                 break;</span>
<span class="lineNum">     470 </span>            :                         }
<span class="lineNum">     471 </span>            : 
<span class="lineNum">     472 </span><span class="lineNoCov">          0 :                         auto curr_data = X.row(data_idx);</span>
<span class="lineNum">     473 </span><span class="lineNoCov">          0 :                         for (int j = 0; j &lt; input_size; ++j)</span>
<span class="lineNum">     474 </span>            :                         {
<span class="lineNum">     475 </span><span class="lineNoCov">          0 :                                 double val = curr_data[j];</span>
<span class="lineNum">     476 </span><span class="lineNoCov">          0 :                                 if (ValidOffsetScale())</span>
<span class="lineNum">     477 </span>            :                                 {
<span class="lineNum">     478 </span><span class="lineNoCov">          0 :                                         val += mInputOffset[j];</span>
<span class="lineNum">     479 </span><span class="lineNoCov">          0 :                                         val = val * mInputScale[j];</span>
<span class="lineNum">     480 </span>            :                                 }
<span class="lineNum">     481 </span><span class="lineNoCov">          0 :                                 data[i * input_size + j] = val;</span>
<span class="lineNum">     482 </span>            :                         }
<span class="lineNum">     483 </span>            :                 }
<span class="lineNum">     484 </span><span class="lineNoCov">          0 :                 data_layer-&gt;AddData(data);</span>
<span class="lineNum">     485 </span>            : 
<span class="lineNum">     486 </span><span class="lineNoCov">          0 :                 tNNData loss = 0;</span>
<span class="lineNum">     487 </span><span class="lineNoCov">          0 :                 net-&gt;ForwardPrefilled(&amp;loss);</span>
<span class="lineNum">     488 </span>            : 
<span class="lineNum">     489 </span><span class="lineNoCov">          0 :                 const std::string&amp; output_layer_name = GetOutputLayerName();</span>
<span class="lineNum">     490 </span><span class="lineNoCov">          0 :                 const auto output_blob = net-&gt;blob_by_name(output_layer_name);</span>
<span class="lineNum">     491 </span><span class="lineNoCov">          0 :                 int output_blob_count = output_blob-&gt;count();</span>
<span class="lineNum">     492 </span><span class="lineNoCov">          0 :                 assert(output_blob_count == batch_size * output_size);</span>
<span class="lineNum">     493 </span>            : 
<span class="lineNum">     494 </span><span class="lineNoCov">          0 :                 auto output_blob_data = output_blob-&gt;cpu_data();</span>
<span class="lineNum">     495 </span><span class="lineNoCov">          0 :                 for (int i = 0; i &lt; batch_size; ++i)</span>
<span class="lineNum">     496 </span>            :                 {
<span class="lineNum">     497 </span><span class="lineNoCov">          0 :                         int data_idx = b * batch_size + i;</span>
<span class="lineNum">     498 </span><span class="lineNoCov">          0 :                         auto curr_data = out_Y.row(data_idx);</span>
<span class="lineNum">     499 </span>            : 
<span class="lineNum">     500 </span><span class="lineNoCov">          0 :                         for (int j = 0; j &lt; output_size; ++j)</span>
<span class="lineNum">     501 </span>            :                         {
<span class="lineNum">     502 </span><span class="lineNoCov">          0 :                                 double val = output_blob_data[i * output_size + j];</span>
<span class="lineNum">     503 </span><span class="lineNoCov">          0 :                                 if (ValidOffsetScale())</span>
<span class="lineNum">     504 </span>            :                                 {
<span class="lineNum">     505 </span><span class="lineNoCov">          0 :                                         val /= mOutputScale[j];</span>
<span class="lineNum">     506 </span><span class="lineNoCov">          0 :                                         val -= mOutputOffset[j];</span>
<span class="lineNum">     507 </span>            :                                 }
<span class="lineNum">     508 </span><span class="lineNoCov">          0 :                                 curr_data(j) = val;</span>
<span class="lineNum">     509 </span>            :                         }
<span class="lineNum">     510 </span>            :                 }
<span class="lineNum">     511 </span>            :         }
<span class="lineNum">     512 </span><span class="lineNoCov">          0 : }</span>
<a name="513"><span class="lineNum">     513 </span>            : </a>
<span class="lineNum">     514 </span>            : 
<span class="lineNum">     515 </span><span class="lineNoCov">          0 : int cNeuralNet::GetInputSize() const</span>
<span class="lineNum">     516 </span>            : {
<span class="lineNum">     517 </span><span class="lineNoCov">          0 :         int size = 0;</span>
<span class="lineNum">     518 </span><span class="lineNoCov">          0 :         if (HasNet())</span>
<span class="lineNum">     519 </span>            :         {
<span class="lineNum">     520 </span><span class="lineNoCov">          0 :                 size = mNet-&gt;input_blobs()[0]-&gt;count();</span>
<span class="lineNum">     521 </span>            :         }
<span class="lineNum">     522 </span><span class="lineNoCov">          0 :         else if (HasSolver())</span>
<span class="lineNum">     523 </span>            :         {
<span class="lineNum">     524 </span><span class="lineNoCov">          0 :                 auto net = GetTrainNet();</span>
<span class="lineNum">     525 </span><span class="lineNoCov">          0 :                 auto input_blob = net-&gt;blob_by_name(GetInputLayerName());</span>
<span class="lineNum">     526 </span><span class="lineNoCov">          0 :                 size = input_blob-&gt;count();</span>
<span class="lineNum">     527 </span><span class="lineNoCov">          0 :                 size /= GetBatchSize();</span>
<span class="lineNum">     528 </span>            :         }
<span class="lineNum">     529 </span><span class="lineNoCov">          0 :         return size;</span>
<a name="530"><span class="lineNum">     530 </span>            : }</a>
<span class="lineNum">     531 </span>            : 
<span class="lineNum">     532 </span><span class="lineNoCov">          0 : int cNeuralNet::GetOutputSize() const</span>
<span class="lineNum">     533 </span>            : {
<span class="lineNum">     534 </span><span class="lineNoCov">          0 :         int size = 0;</span>
<span class="lineNum">     535 </span><span class="lineNoCov">          0 :         if (HasNet())</span>
<span class="lineNum">     536 </span>            :         {
<span class="lineNum">     537 </span><span class="lineNoCov">          0 :                 size = mNet-&gt;output_blobs()[0]-&gt;count();</span>
<span class="lineNum">     538 </span>            :         }
<span class="lineNum">     539 </span><span class="lineNoCov">          0 :         else if (HasSolver())</span>
<span class="lineNum">     540 </span>            :         {
<span class="lineNum">     541 </span><span class="lineNoCov">          0 :                 auto net = GetTrainNet();</span>
<span class="lineNum">     542 </span><span class="lineNoCov">          0 :                 auto output_blob = net-&gt;blob_by_name(GetOutputLayerName());</span>
<span class="lineNum">     543 </span><span class="lineNoCov">          0 :                 size = output_blob-&gt;count();</span>
<span class="lineNum">     544 </span><span class="lineNoCov">          0 :                 size /= GetBatchSize();</span>
<span class="lineNum">     545 </span>            :         }
<span class="lineNum">     546 </span>            : 
<span class="lineNum">     547 </span><span class="lineNoCov">          0 :         return size;</span>
<a name="548"><span class="lineNum">     548 </span>            : }</a>
<span class="lineNum">     549 </span>            : 
<span class="lineNum">     550 </span><span class="lineNoCov">          0 : int cNeuralNet::GetBatchSize() const</span>
<span class="lineNum">     551 </span>            : {
<span class="lineNum">     552 </span><span class="lineNoCov">          0 :         int batch_size = 0;</span>
<span class="lineNum">     553 </span><span class="lineNoCov">          0 :         if (HasSolver())</span>
<span class="lineNum">     554 </span>            :         {
<span class="lineNum">     555 </span><span class="lineNoCov">          0 :                 auto data_layer = GetTrainDataLayer();</span>
<span class="lineNum">     556 </span><span class="lineNoCov">          0 :                 batch_size = data_layer-&gt;batch_size();</span>
<span class="lineNum">     557 </span>            :         }
<span class="lineNum">     558 </span><span class="lineNoCov">          0 :         return batch_size;</span>
<a name="559"><span class="lineNum">     559 </span>            : }</a>
<span class="lineNum">     560 </span>            : 
<span class="lineNum">     561 </span><span class="lineNoCov">          0 : int cNeuralNet::CalcNumParams() const</span>
<span class="lineNum">     562 </span>            : {
<span class="lineNum">     563 </span><span class="lineNoCov">          0 :         int num_params = 0;</span>
<span class="lineNum">     564 </span><span class="lineNoCov">          0 :         if (HasNet())</span>
<span class="lineNum">     565 </span>            :         {
<span class="lineNum">     566 </span><span class="lineNoCov">          0 :                 num_params = CalcNumParams(*mNet);</span>
<span class="lineNum">     567 </span>            :         }
<span class="lineNum">     568 </span><span class="lineNoCov">          0 :         return num_params;</span>
<a name="569"><span class="lineNum">     569 </span>            : }</a>
<span class="lineNum">     570 </span>            : 
<span class="lineNum">     571 </span><span class="lineNoCov">          0 : void cNeuralNet::OutputModel(const std::string&amp; out_file) const</span>
<span class="lineNum">     572 </span>            : {
<span class="lineNum">     573 </span><span class="lineNoCov">          0 :         if (HasNet())</span>
<span class="lineNum">     574 </span>            :         {
<span class="lineNum">     575 </span>            :                 {
<span class="lineNum">     576 </span>            :                         // arg, hdf5 doesn't seem to be threadsafe
<span class="lineNum">     577 </span><span class="lineNoCov">          0 :                         std::lock_guard&lt;std::mutex&gt; output_lock(gOutputLock);</span>
<span class="lineNum">     578 </span><span class="lineNoCov">          0 :                         mNet-&gt;ToHDF5(out_file);</span>
<span class="lineNum">     579 </span>            :                 }
<span class="lineNum">     580 </span><span class="lineNoCov">          0 :                 std::string scale_file = GetOffsetScaleFile(out_file);</span>
<span class="lineNum">     581 </span><span class="lineNoCov">          0 :                 WriteOffsetScale(scale_file);</span>
<span class="lineNum">     582 </span>            :         }
<span class="lineNum">     583 </span>            :         else
<span class="lineNum">     584 </span>            :         {
<span class="lineNum">     585 </span><span class="lineNoCov">          0 :                 printf(&quot;No valid net to output\n&quot;);</span>
<span class="lineNum">     586 </span>            :         }
<a name="587"><span class="lineNum">     587 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     588 </span>            : 
<span class="lineNum">     589 </span><span class="lineNoCov">          0 : void cNeuralNet::PrintParams() const</span>
<span class="lineNum">     590 </span>            : {
<span class="lineNum">     591 </span><span class="lineNoCov">          0 :         PrintParams(*mNet);</span>
<a name="592"><span class="lineNum">     592 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     593 </span>            : 
<span class="lineNum">     594 </span><span class="lineNoCov">          0 : void cNeuralNet::PrintParams(const caffe::Net&lt;tNNData&gt;&amp; net)</span>
<span class="lineNum">     595 </span>            : {
<span class="lineNum">     596 </span><span class="lineNoCov">          0 :         const auto&amp; param_blobs = net.learnable_params();</span>
<span class="lineNum">     597 </span><span class="lineNoCov">          0 :         int num_blobs = static_cast&lt;int&gt;(param_blobs.size());</span>
<span class="lineNum">     598 </span>            : 
<span class="lineNum">     599 </span><span class="lineNoCov">          0 :         for (int b = 0; b &lt; num_blobs; ++b)</span>
<span class="lineNum">     600 </span>            :         {
<span class="lineNum">     601 </span><span class="lineNoCov">          0 :                 printf(&quot;Params %i:\n&quot;, b);</span>
<span class="lineNum">     602 </span><span class="lineNoCov">          0 :                 auto blob = param_blobs[b];</span>
<span class="lineNum">     603 </span><span class="lineNoCov">          0 :                 auto blob_data = blob-&gt;cpu_data();</span>
<span class="lineNum">     604 </span><span class="lineNoCov">          0 :                 int blob_count = blob-&gt;count();</span>
<span class="lineNum">     605 </span><span class="lineNoCov">          0 :                 for (int i = 0; i &lt; blob_count; ++i)</span>
<span class="lineNum">     606 </span>            :                 {
<span class="lineNum">     607 </span><span class="lineNoCov">          0 :                         printf(&quot;%.5f\n&quot;, blob_data[i]);</span>
<span class="lineNum">     608 </span>            :                 }
<span class="lineNum">     609 </span>            :         }
<a name="610"><span class="lineNum">     610 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     611 </span>            : 
<span class="lineNum">     612 </span><span class="lineNoCov">          0 : int cNeuralNet::CalcNumParams(const caffe::Net&lt;tNNData&gt;&amp; net)</span>
<span class="lineNum">     613 </span>            : {
<span class="lineNum">     614 </span><span class="lineNoCov">          0 :         auto layers = net.layers();</span>
<span class="lineNum">     615 </span><span class="lineNoCov">          0 :         const auto&amp; param_blobs = net.learnable_params();</span>
<span class="lineNum">     616 </span><span class="lineNoCov">          0 :         int num_params = 0;</span>
<span class="lineNum">     617 </span><span class="lineNoCov">          0 :         int num_blobs = static_cast&lt;int&gt;(param_blobs.size());</span>
<span class="lineNum">     618 </span>            : 
<span class="lineNum">     619 </span><span class="lineNoCov">          0 :         for (int b = 0; b &lt; num_blobs; ++b)</span>
<span class="lineNum">     620 </span>            :         {
<span class="lineNum">     621 </span><span class="lineNoCov">          0 :                 const auto&amp; blob = param_blobs[b];</span>
<span class="lineNum">     622 </span><span class="lineNoCov">          0 :                 int count = blob-&gt;count();</span>
<span class="lineNum">     623 </span><span class="lineNoCov">          0 :                 num_params += count;</span>
<span class="lineNum">     624 </span>            :         }
<span class="lineNum">     625 </span>            : 
<span class="lineNum">     626 </span><span class="lineNoCov">          0 :         return num_params;</span>
<a name="627"><span class="lineNum">     627 </span>            : }</a>
<span class="lineNum">     628 </span>            : 
<span class="lineNum">     629 </span><span class="lineNoCov">          0 : void cNeuralNet::CopyModel(const caffe::Net&lt;tNNData&gt;&amp; src, caffe::Net&lt;tNNData&gt;&amp; dst)</span>
<span class="lineNum">     630 </span>            : {
<span class="lineNum">     631 </span><span class="lineNoCov">          0 :         const auto&amp; src_params = src.learnable_params();</span>
<span class="lineNum">     632 </span><span class="lineNoCov">          0 :         const auto&amp; dst_params = dst.learnable_params();</span>
<span class="lineNum">     633 </span><span class="lineNoCov">          0 :         CopyParams(src_params, dst_params);</span>
<a name="634"><span class="lineNum">     634 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     635 </span>            : 
<span class="lineNum">     636 </span><span class="lineNoCov">          0 : void cNeuralNet::CopyParams(const std::vector&lt;caffe::Blob&lt;tNNData&gt;*&gt;&amp; src_params, const std::vector&lt;caffe::Blob&lt;tNNData&gt;*&gt;&amp; dst_params)</span>
<span class="lineNum">     637 </span>            : {
<span class="lineNum">     638 </span><span class="lineNoCov">          0 :         int num_blobs = static_cast&lt;int&gt;(src_params.size());</span>
<span class="lineNum">     639 </span><span class="lineNoCov">          0 :         for (int b = 0; b &lt; num_blobs; ++b)</span>
<span class="lineNum">     640 </span>            :         {
<span class="lineNum">     641 </span><span class="lineNoCov">          0 :                 auto src_blob = src_params[b];</span>
<span class="lineNum">     642 </span><span class="lineNoCov">          0 :                 auto dst_blob = dst_params[b];</span>
<span class="lineNum">     643 </span>            : 
<span class="lineNum">     644 </span><span class="lineNoCov">          0 :                 auto src_blob_data = src_blob-&gt;cpu_data();</span>
<span class="lineNum">     645 </span><span class="lineNoCov">          0 :                 auto dst_blob_data = dst_blob-&gt;mutable_cpu_data();</span>
<span class="lineNum">     646 </span><span class="lineNoCov">          0 :                 int src_blob_count = src_blob-&gt;count();</span>
<span class="lineNum">     647 </span><span class="lineNoCov">          0 :                 int dst_blob_count = dst_blob-&gt;count();</span>
<span class="lineNum">     648 </span>            : 
<span class="lineNum">     649 </span><span class="lineNoCov">          0 :                 if (src_blob_count == dst_blob_count)</span>
<span class="lineNum">     650 </span>            :                 {
<span class="lineNum">     651 </span><span class="lineNoCov">          0 :                         std::memcpy(dst_blob_data, src_blob_data, src_blob_count * sizeof(tNNData));</span>
<span class="lineNum">     652 </span>            :                 }
<span class="lineNum">     653 </span>            :                 else
<span class="lineNum">     654 </span>            :                 {
<span class="lineNum">     655 </span><span class="lineNoCov">          0 :                         assert(false); // param size mismatch</span>
<span class="lineNum">     656 </span>            :                 }
<span class="lineNum">     657 </span>            :         }
<a name="658"><span class="lineNum">     658 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     659 </span>            : 
<span class="lineNum">     660 </span><span class="lineNoCov">          0 : bool cNeuralNet::CompareModel(const caffe::Net&lt;tNNData&gt;&amp; a, const caffe::Net&lt;tNNData&gt;&amp; b)</span>
<span class="lineNum">     661 </span>            : {
<span class="lineNum">     662 </span><span class="lineNoCov">          0 :         const auto&amp; a_params = a.learnable_params();</span>
<span class="lineNum">     663 </span><span class="lineNoCov">          0 :         const auto&amp; b_params = b.learnable_params();</span>
<span class="lineNum">     664 </span><span class="lineNoCov">          0 :         return CompareParams(a_params, b_params);</span>
<a name="665"><span class="lineNum">     665 </span>            : }</a>
<span class="lineNum">     666 </span>            : 
<span class="lineNum">     667 </span><span class="lineNoCov">          0 : bool cNeuralNet::CompareParams(const std::vector&lt;caffe::Blob&lt;tNNData&gt;*&gt;&amp; a_params, const std::vector&lt;caffe::Blob&lt;tNNData&gt;*&gt;&amp; b_params)</span>
<span class="lineNum">     668 </span>            : {
<span class="lineNum">     669 </span><span class="lineNoCov">          0 :         int num_blobs = static_cast&lt;int&gt;(a_params.size());</span>
<span class="lineNum">     670 </span><span class="lineNoCov">          0 :         for (int i = 0; i &lt; num_blobs; ++i)</span>
<span class="lineNum">     671 </span>            :         {
<span class="lineNum">     672 </span><span class="lineNoCov">          0 :                 auto a_blob = a_params[i];</span>
<span class="lineNum">     673 </span><span class="lineNoCov">          0 :                 auto b_blob = b_params[i];</span>
<span class="lineNum">     674 </span>            : 
<span class="lineNum">     675 </span><span class="lineNoCov">          0 :                 auto a_blob_data = a_blob-&gt;cpu_data();</span>
<span class="lineNum">     676 </span><span class="lineNoCov">          0 :                 auto b_blob_data = b_blob-&gt;cpu_data();</span>
<span class="lineNum">     677 </span><span class="lineNoCov">          0 :                 int a_blob_count = a_blob-&gt;count();</span>
<span class="lineNum">     678 </span><span class="lineNoCov">          0 :                 int b_blob_count = b_blob-&gt;count();</span>
<span class="lineNum">     679 </span>            : 
<span class="lineNum">     680 </span><span class="lineNoCov">          0 :                 if (a_blob_count == b_blob_count)</span>
<span class="lineNum">     681 </span>            :                 {
<span class="lineNum">     682 </span><span class="lineNoCov">          0 :                         for (int j = 0; j &lt; a_blob_count; ++j)</span>
<span class="lineNum">     683 </span>            :                         {
<span class="lineNum">     684 </span><span class="lineNoCov">          0 :                                 if (a_blob_data[j] != b_blob_data[j])</span>
<span class="lineNum">     685 </span>            :                                 {
<span class="lineNum">     686 </span><span class="lineNoCov">          0 :                                         return false;</span>
<span class="lineNum">     687 </span>            :                                 }
<span class="lineNum">     688 </span>            :                         }
<span class="lineNum">     689 </span>            :                 }
<span class="lineNum">     690 </span>            :                 else
<span class="lineNum">     691 </span>            :                 {
<span class="lineNum">     692 </span><span class="lineNoCov">          0 :                         assert(false); // param size mismatch</span>
<span class="lineNum">     693 </span>            :                 }
<span class="lineNum">     694 </span>            :         }
<span class="lineNum">     695 </span><span class="lineNoCov">          0 :         return true;</span>
<a name="696"><span class="lineNum">     696 </span>            : }</a>
<span class="lineNum">     697 </span>            : 
<span class="lineNum">     698 </span><span class="lineCov">        117 : bool cNeuralNet::HasNet() const</span>
<span class="lineNum">     699 </span>            : {
<span class="lineNum">     700 </span><span class="lineCov">        117 :         return mNet != nullptr;</span>
<a name="701"><span class="lineNum">     701 </span>            : }</a>
<span class="lineNum">     702 </span>            : 
<span class="lineNum">     703 </span><span class="lineNoCov">          0 : bool cNeuralNet::HasSolver() const</span>
<span class="lineNum">     704 </span>            : {
<span class="lineNum">     705 </span><span class="lineNoCov">          0 :         return mSolver != nullptr;</span>
<a name="706"><span class="lineNum">     706 </span>            : }</a>
<span class="lineNum">     707 </span>            : 
<span class="lineNum">     708 </span><span class="lineNoCov">          0 : bool cNeuralNet::HasLayer(const std::string layer_name) const</span>
<span class="lineNum">     709 </span>            : {
<span class="lineNum">     710 </span><span class="lineNoCov">          0 :         if (HasNet())</span>
<span class="lineNum">     711 </span>            :         {
<span class="lineNum">     712 </span><span class="lineNoCov">          0 :                 return mNet-&gt;has_blob(layer_name) &amp;&amp; mNet-&gt;has_layer(layer_name);</span>
<span class="lineNum">     713 </span>            :         }
<span class="lineNum">     714 </span><span class="lineNoCov">          0 :         return false;</span>
<a name="715"><span class="lineNum">     715 </span>            : }</a>
<span class="lineNum">     716 </span>            : 
<span class="lineNum">     717 </span><span class="lineNoCov">          0 : bool cNeuralNet::HasValidModel() const</span>
<span class="lineNum">     718 </span>            : {
<span class="lineNum">     719 </span><span class="lineNoCov">          0 :         return mValidModel;</span>
<a name="720"><span class="lineNum">     720 </span>            : }</a>
<span class="lineNum">     721 </span>            : 
<span class="lineNum">     722 </span><span class="lineNoCov">          0 : void cNeuralNet::CopyModel(const cNeuralNet&amp; other)</span>
<span class="lineNum">     723 </span>            : {
<span class="lineNum">     724 </span><span class="lineNoCov">          0 :         CopyParams(other.GetParams(), GetParams());</span>
<span class="lineNum">     725 </span>            : 
<span class="lineNum">     726 </span><span class="lineNoCov">          0 :         mInputOffset = other.GetInputOffset();</span>
<span class="lineNum">     727 </span><span class="lineNoCov">          0 :         mInputScale = other.GetInputScale();</span>
<span class="lineNum">     728 </span><span class="lineNoCov">          0 :         mOutputOffset = other.GetOutputOffset();</span>
<span class="lineNum">     729 </span><span class="lineNoCov">          0 :         mOutputScale = other.GetOutputScale();</span>
<span class="lineNum">     730 </span>            : 
<span class="lineNum">     731 </span><span class="lineNoCov">          0 :         SyncSolverParams();</span>
<span class="lineNum">     732 </span><span class="lineNoCov">          0 :         mValidModel = true;</span>
<a name="733"><span class="lineNum">     733 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     734 </span>            : 
<span class="lineNum">     735 </span><span class="lineNoCov">          0 : void cNeuralNet::LerpModel(const cNeuralNet&amp; other, double lerp)</span>
<span class="lineNum">     736 </span>            : {
<span class="lineNum">     737 </span><span class="lineNoCov">          0 :         BlendModel(other, 1 - lerp, lerp);</span>
<a name="738"><span class="lineNum">     738 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     739 </span>            : 
<span class="lineNum">     740 </span><span class="lineNoCov">          0 : void cNeuralNet::BlendModel(const cNeuralNet&amp; other, double this_weight, double other_weight)</span>
<span class="lineNum">     741 </span>            : {
<span class="lineNum">     742 </span><span class="lineNoCov">          0 :         const auto&amp; src_params = other.GetParams();</span>
<span class="lineNum">     743 </span><span class="lineNoCov">          0 :         const auto&amp; dst_params = GetParams();</span>
<span class="lineNum">     744 </span>            : 
<span class="lineNum">     745 </span><span class="lineNoCov">          0 :         int num_blobs = static_cast&lt;int&gt;(src_params.size());</span>
<span class="lineNum">     746 </span><span class="lineNoCov">          0 :         for (int b = 0; b &lt; num_blobs; ++b)</span>
<span class="lineNum">     747 </span>            :         {
<span class="lineNum">     748 </span><span class="lineNoCov">          0 :                 auto src_blob = src_params[b];</span>
<span class="lineNum">     749 </span><span class="lineNoCov">          0 :                 auto dst_blob = dst_params[b];</span>
<span class="lineNum">     750 </span>            : 
<span class="lineNum">     751 </span><span class="lineNoCov">          0 :                 auto src_blob_data = src_blob-&gt;cpu_data();</span>
<span class="lineNum">     752 </span><span class="lineNoCov">          0 :                 auto dst_blob_data = dst_blob-&gt;mutable_cpu_data();</span>
<span class="lineNum">     753 </span><span class="lineNoCov">          0 :                 int src_blob_count = src_blob-&gt;count();</span>
<span class="lineNum">     754 </span><span class="lineNoCov">          0 :                 int dst_blob_count = dst_blob-&gt;count();</span>
<span class="lineNum">     755 </span><span class="lineNoCov">          0 :                 assert(src_blob_count == dst_blob_count);</span>
<span class="lineNum">     756 </span>            : 
<span class="lineNum">     757 </span><span class="lineNoCov">          0 :                 for (int i = 0; i &lt; src_blob_count; ++i)</span>
<span class="lineNum">     758 </span>            :                 {
<span class="lineNum">     759 </span><span class="lineNoCov">          0 :                         dst_blob_data[i] = this_weight * dst_blob_data[i] + other_weight * src_blob_data[i];</span>
<span class="lineNum">     760 </span>            :                 }
<span class="lineNum">     761 </span>            :         }
<span class="lineNum">     762 </span>            : 
<span class="lineNum">     763 </span><span class="lineNoCov">          0 :         SyncSolverParams();</span>
<span class="lineNum">     764 </span><span class="lineNoCov">          0 :         mValidModel = true;</span>
<a name="765"><span class="lineNum">     765 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     766 </span>            : 
<span class="lineNum">     767 </span><span class="lineNoCov">          0 : void cNeuralNet::BuildNetParams(caffe::NetParameter&amp; out_params) const</span>
<span class="lineNum">     768 </span>            : {
<span class="lineNum">     769 </span><span class="lineNoCov">          0 :         mNet-&gt;ToProto(&amp;out_params);</span>
<a name="770"><span class="lineNum">     770 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     771 </span>            : 
<span class="lineNum">     772 </span><span class="lineNoCov">          0 : bool cNeuralNet::CompareModel(const cNeuralNet&amp; other) const</span>
<span class="lineNum">     773 </span>            : {
<span class="lineNum">     774 </span><span class="lineNoCov">          0 :         bool same = CompareParams(other.GetParams(), GetParams());</span>
<span class="lineNum">     775 </span>            : 
<span class="lineNum">     776 </span><span class="lineNoCov">          0 :         same &amp;= mInputOffset.isApprox(other.GetInputOffset(), 0);</span>
<span class="lineNum">     777 </span><span class="lineNoCov">          0 :         same &amp;= mInputScale.isApprox(other.GetInputScale(), 0);</span>
<span class="lineNum">     778 </span><span class="lineNoCov">          0 :         same &amp;= mOutputOffset.isApprox(other.GetOutputOffset(), 0);</span>
<span class="lineNum">     779 </span><span class="lineNoCov">          0 :         same &amp;= mOutputScale.isApprox(other.GetOutputScale(), 0);</span>
<span class="lineNum">     780 </span>            : 
<span class="lineNum">     781 </span><span class="lineNoCov">          0 :         return same;</span>
<a name="782"><span class="lineNum">     782 </span>            : }</a>
<span class="lineNum">     783 </span>            : 
<span class="lineNum">     784 </span><span class="lineNoCov">          0 : void cNeuralNet::ForwardInjectNoisePrefilled(double mean, double stdev, const std::string&amp; layer_name, Eigen::VectorXd&amp; out_y) const</span>
<span class="lineNum">     785 </span>            : {
<span class="lineNum">     786 </span>            :         // assume the Eval has already been called which fills the blobs in the network using a given input
<span class="lineNum">     787 </span><span class="lineNoCov">          0 :         if (HasLayer(layer_name))</span>
<span class="lineNum">     788 </span>            :         {
<span class="lineNum">     789 </span><span class="lineNoCov">          0 :                 auto blob = mNet-&gt;blob_by_name(layer_name);</span>
<span class="lineNum">     790 </span>            : 
<span class="lineNum">     791 </span><span class="lineNoCov">          0 :                 tNNData* data = blob-&gt;mutable_cpu_data();</span>
<span class="lineNum">     792 </span><span class="lineNoCov">          0 :                 const int data_size = blob-&gt;count();</span>
<span class="lineNum">     793 </span>            : 
<span class="lineNum">     794 </span><span class="lineNoCov">          0 :                 for (int i = 0; i &lt; data_size; ++i)</span>
<span class="lineNum">     795 </span>            :                 {
<span class="lineNum">     796 </span><span class="lineNoCov">          0 :                         double noise = cMathUtil::RandDoubleNorm(mean, stdev);</span>
<span class="lineNum">     797 </span><span class="lineNoCov">          0 :                         data[i] += noise;</span>
<span class="lineNum">     798 </span>            :                 }
<span class="lineNum">     799 </span>            : 
<span class="lineNum">     800 </span><span class="lineNoCov">          0 :                 int layer_idx = mNet-&gt;GetLayerIdx(layer_name);</span>
<span class="lineNum">     801 </span><span class="lineNoCov">          0 :                 ++layer_idx;</span>
<span class="lineNum">     802 </span><span class="lineNoCov">          0 :                 mNet-&gt;ForwardFrom(layer_idx);</span>
<span class="lineNum">     803 </span>            : 
<span class="lineNum">     804 </span><span class="lineNoCov">          0 :                 const std::vector&lt;caffe::Blob&lt;tNNData&gt;*&gt;&amp; result_arr = mNet-&gt;output_blobs();</span>
<span class="lineNum">     805 </span><span class="lineNoCov">          0 :                 FetchOutput(result_arr, out_y);</span>
<span class="lineNum">     806 </span>            :         }
<span class="lineNum">     807 </span>            :         else
<span class="lineNum">     808 </span>            :         {
<span class="lineNum">     809 </span><span class="lineNoCov">          0 :                 printf(&quot;Can't find layer named %s\n&quot;, layer_name.c_str());</span>
<span class="lineNum">     810 </span><span class="lineNoCov">          0 :                 assert(false); // layer not found</span>
<span class="lineNum">     811 </span>            :         }
<a name="812"><span class="lineNum">     812 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     813 </span>            : 
<span class="lineNum">     814 </span><span class="lineNoCov">          0 : void cNeuralNet::GetLayerState(const std::string&amp; layer_name, Eigen::VectorXd&amp; out_state) const</span>
<span class="lineNum">     815 </span>            : {
<span class="lineNum">     816 </span><span class="lineNoCov">          0 :         auto blob = mNet-&gt;blob_by_name(layer_name);</span>
<span class="lineNum">     817 </span><span class="lineNoCov">          0 :         if (blob != nullptr)</span>
<span class="lineNum">     818 </span>            :         {
<span class="lineNum">     819 </span><span class="lineNoCov">          0 :                 const tNNData* data = blob-&gt;cpu_data();</span>
<span class="lineNum">     820 </span><span class="lineNoCov">          0 :                 const int data_size = blob-&gt;count();</span>
<span class="lineNum">     821 </span>            : 
<span class="lineNum">     822 </span><span class="lineNoCov">          0 :                 out_state.resize(data_size);</span>
<span class="lineNum">     823 </span><span class="lineNoCov">          0 :                 for (int i = 0; i &lt; data_size; ++i)</span>
<span class="lineNum">     824 </span>            :                 {
<span class="lineNum">     825 </span><span class="lineNoCov">          0 :                         out_state[i] = data[i];</span>
<span class="lineNum">     826 </span>            :                 }
<span class="lineNum">     827 </span>            :         }
<span class="lineNum">     828 </span>            :         else
<span class="lineNum">     829 </span>            :         {
<span class="lineNum">     830 </span><span class="lineNoCov">          0 :                 printf(&quot;Can't find layer named %s\n&quot;, layer_name.c_str());</span>
<span class="lineNum">     831 </span><span class="lineNoCov">          0 :                 assert(false); // layer not found</span>
<span class="lineNum">     832 </span>            :         }
<a name="833"><span class="lineNum">     833 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     834 </span>            : 
<span class="lineNum">     835 </span><span class="lineNoCov">          0 : void cNeuralNet::SetLayerState(const Eigen::VectorXd&amp; state, const std::string&amp; layer_name) const</span>
<span class="lineNum">     836 </span>            : {
<span class="lineNum">     837 </span><span class="lineNoCov">          0 :         auto blob = mNet-&gt;blob_by_name(layer_name);</span>
<span class="lineNum">     838 </span><span class="lineNoCov">          0 :         if (blob != nullptr)</span>
<span class="lineNum">     839 </span>            :         {
<span class="lineNum">     840 </span><span class="lineNoCov">          0 :                 tNNData* data = blob-&gt;mutable_cpu_data();</span>
<span class="lineNum">     841 </span><span class="lineNoCov">          0 :                 const int data_size = blob-&gt;count();</span>
<span class="lineNum">     842 </span><span class="lineNoCov">          0 :                 assert(state.size() == data_size);</span>
<span class="lineNum">     843 </span>            : 
<span class="lineNum">     844 </span><span class="lineNoCov">          0 :                 for (int i = 0; i &lt; data_size; ++i)</span>
<span class="lineNum">     845 </span>            :                 {
<span class="lineNum">     846 </span><span class="lineNoCov">          0 :                         data[i] = state[i];</span>
<span class="lineNum">     847 </span>            :                 }
<span class="lineNum">     848 </span>            :         }
<span class="lineNum">     849 </span>            :         else
<span class="lineNum">     850 </span>            :         {
<span class="lineNum">     851 </span><span class="lineNoCov">          0 :                 printf(&quot;Can't find layer named %s\n&quot;, layer_name.c_str());</span>
<span class="lineNum">     852 </span><span class="lineNoCov">          0 :                 assert(false); // layer not found</span>
<span class="lineNum">     853 </span>            :         }
<a name="854"><span class="lineNum">     854 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     855 </span>            : 
<span class="lineNum">     856 </span><span class="lineNoCov">          0 : const std::vector&lt;caffe::Blob&lt;cNeuralNet::tNNData&gt;*&gt;&amp; cNeuralNet::GetParams() const</span>
<span class="lineNum">     857 </span>            : {
<span class="lineNum">     858 </span><span class="lineNoCov">          0 :         if (HasNet())</span>
<span class="lineNum">     859 </span>            :         {
<span class="lineNum">     860 </span><span class="lineNoCov">          0 :                 return mNet-&gt;learnable_params();</span>
<span class="lineNum">     861 </span>            :         }
<span class="lineNum">     862 </span>            :         else
<span class="lineNum">     863 </span>            :         {
<span class="lineNum">     864 </span><span class="lineNoCov">          0 :                 auto net = GetTrainNet();</span>
<span class="lineNum">     865 </span><span class="lineNoCov">          0 :                 return net-&gt;learnable_params();</span>
<span class="lineNum">     866 </span>            :         }
<a name="867"><span class="lineNum">     867 </span>            : }</a>
<span class="lineNum">     868 </span>            : 
<span class="lineNum">     869 </span><span class="lineNoCov">          0 : void cNeuralNet::SyncSolverParams()</span>
<span class="lineNum">     870 </span>            : {
<span class="lineNum">     871 </span><span class="lineNoCov">          0 :         if (HasSolver() &amp;&amp; HasNet())</span>
<span class="lineNum">     872 </span>            :         {
<span class="lineNum">     873 </span><span class="lineNoCov">          0 :                 CopyModel(*mNet, *GetTrainNet());</span>
<span class="lineNum">     874 </span>            :         }
<a name="875"><span class="lineNum">     875 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     876 </span>            : 
<span class="lineNum">     877 </span><span class="lineNoCov">          0 : void cNeuralNet::SyncNetParams()</span>
<span class="lineNum">     878 </span>            : {
<span class="lineNum">     879 </span><span class="lineNoCov">          0 :         if (HasSolver() &amp;&amp; HasNet())</span>
<span class="lineNum">     880 </span>            :         {
<span class="lineNum">     881 </span><span class="lineNoCov">          0 :                 CopyModel(*GetTrainNet(), *mNet);</span>
<span class="lineNum">     882 </span>            :         }
<a name="883"><span class="lineNum">     883 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     884 </span>            : 
<span class="lineNum">     885 </span><span class="lineNoCov">          0 : void cNeuralNet::CopyGrad(const cNeuralNet&amp; other)</span>
<span class="lineNum">     886 </span>            : {
<span class="lineNum">     887 </span><span class="lineNoCov">          0 :         assert(HasSolver());</span>
<span class="lineNum">     888 </span><span class="lineNoCov">          0 :         assert(other.HasSolver());</span>
<span class="lineNum">     889 </span><span class="lineNoCov">          0 :         auto other_net = other.GetTrainNet();</span>
<span class="lineNum">     890 </span><span class="lineNoCov">          0 :         auto this_net = GetTrainNet();</span>
<span class="lineNum">     891 </span>            :         
<span class="lineNum">     892 </span><span class="lineNoCov">          0 :         auto other_params = other_net-&gt;learnable_params();</span>
<span class="lineNum">     893 </span><span class="lineNoCov">          0 :         auto this_params = this_net-&gt;learnable_params();</span>
<span class="lineNum">     894 </span><span class="lineNoCov">          0 :         assert(other_params.size() == this_params.size());</span>
<span class="lineNum">     895 </span>            : 
<span class="lineNum">     896 </span><span class="lineNoCov">          0 :         for (size_t i = 0; i &lt; this_params.size(); ++i)</span>
<span class="lineNum">     897 </span>            :         {
<span class="lineNum">     898 </span><span class="lineNoCov">          0 :                 auto other_blob = other_params[i];</span>
<span class="lineNum">     899 </span><span class="lineNoCov">          0 :                 auto this_blob = this_params[i];</span>
<span class="lineNum">     900 </span><span class="lineNoCov">          0 :                 assert(other_blob-&gt;count() == this_blob-&gt;count());</span>
<span class="lineNum">     901 </span>            : 
<span class="lineNum">     902 </span><span class="lineNoCov">          0 :                 auto other_diff = other_blob-&gt;cpu_diff();</span>
<span class="lineNum">     903 </span><span class="lineNoCov">          0 :                 auto this_diff = this_blob-&gt;mutable_cpu_diff();</span>
<span class="lineNum">     904 </span><span class="lineNoCov">          0 :                 auto other_data = other_blob-&gt;cpu_data();</span>
<span class="lineNum">     905 </span><span class="lineNoCov">          0 :                 auto this_data = this_blob-&gt;cpu_data();</span>
<span class="lineNum">     906 </span><span class="lineNoCov">          0 :                 for (int j = 0; j &lt; this_blob-&gt;count(); ++j)</span>
<span class="lineNum">     907 </span>            :                 {
<span class="lineNum">     908 </span><span class="lineNoCov">          0 :                         this_diff[j] = other_diff[j];</span>
<span class="lineNum">     909 </span>            :                 }
<span class="lineNum">     910 </span>            :         }
<a name="911"><span class="lineNum">     911 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     912 </span>            : 
<span class="lineNum">     913 </span><span class="lineNoCov">          0 : bool cNeuralNet::ValidOffsetScale() const</span>
<span class="lineNum">     914 </span>            : {
<span class="lineNum">     915 </span><span class="lineNoCov">          0 :         return mInputOffset.size() &gt; 0 &amp;&amp; mInputScale.size() &gt; 0</span>
<span class="lineNum">     916 </span><span class="lineNoCov">          0 :                 &amp;&amp; mOutputOffset.size() &gt; 0 &amp;&amp; mOutputScale.size() &gt; 0;</span>
<a name="917"><span class="lineNum">     917 </span>            : }</a>
<span class="lineNum">     918 </span>            : 
<span class="lineNum">     919 </span><span class="lineNoCov">          0 : void cNeuralNet::InitOffsetScale()</span>
<span class="lineNum">     920 </span>            : {
<span class="lineNum">     921 </span><span class="lineNoCov">          0 :         int input_size = GetInputSize();</span>
<span class="lineNum">     922 </span><span class="lineNoCov">          0 :         mInputOffset = Eigen::VectorXd::Zero(input_size);</span>
<span class="lineNum">     923 </span><span class="lineNoCov">          0 :         mInputScale = Eigen::VectorXd::Ones(input_size);</span>
<span class="lineNum">     924 </span>            : 
<span class="lineNum">     925 </span><span class="lineNoCov">          0 :         int output_size = GetOutputSize();</span>
<span class="lineNum">     926 </span><span class="lineNoCov">          0 :         mOutputOffset = Eigen::VectorXd::Zero(output_size);</span>
<span class="lineNum">     927 </span><span class="lineNoCov">          0 :         mOutputScale = Eigen::VectorXd::Ones(output_size);</span>
<a name="928"><span class="lineNum">     928 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     929 </span>            : 
<span class="lineNum">     930 </span><span class="lineNoCov">          0 : void cNeuralNet::FetchOutput(const std::vector&lt;caffe::Blob&lt;tNNData&gt;*&gt;&amp; results_arr, Eigen::VectorXd&amp; out_y) const</span>
<span class="lineNum">     931 </span>            : {
<span class="lineNum">     932 </span><span class="lineNoCov">          0 :         const caffe::Blob&lt;tNNData&gt;* result = results_arr[0];</span>
<span class="lineNum">     933 </span><span class="lineNoCov">          0 :         const tNNData* result_data = result-&gt;cpu_data();</span>
<span class="lineNum">     934 </span>            : 
<span class="lineNum">     935 </span><span class="lineNoCov">          0 :         const int output_size = GetOutputSize();</span>
<span class="lineNum">     936 </span><span class="lineNoCov">          0 :         assert(result-&gt;count() == output_size);</span>
<span class="lineNum">     937 </span><span class="lineNoCov">          0 :         out_y.resize(output_size);</span>
<span class="lineNum">     938 </span>            : 
<span class="lineNum">     939 </span><span class="lineNoCov">          0 :         for (int i = 0; i &lt; output_size; ++i)</span>
<span class="lineNum">     940 </span>            :         {
<span class="lineNum">     941 </span><span class="lineNoCov">          0 :                 out_y[i] = result_data[i];</span>
<span class="lineNum">     942 </span>            :         }
<span class="lineNum">     943 </span>            : 
<span class="lineNum">     944 </span><span class="lineNoCov">          0 :         UnnormalizeOutput(out_y);</span>
<a name="945"><span class="lineNum">     945 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     946 </span>            : 
<span class="lineNum">     947 </span><span class="lineNoCov">          0 : void cNeuralNet::FetchInput(Eigen::VectorXd&amp; out_x) const</span>
<span class="lineNum">     948 </span>            : {
<span class="lineNum">     949 </span><span class="lineNoCov">          0 :         const auto&amp; input_blob = mNet-&gt;input_blobs()[0];</span>
<span class="lineNum">     950 </span><span class="lineNoCov">          0 :         const tNNData*  blob_data = input_blob-&gt;cpu_data();</span>
<span class="lineNum">     951 </span>            : 
<span class="lineNum">     952 </span><span class="lineNoCov">          0 :         int input_size = GetInputSize();</span>
<span class="lineNum">     953 </span><span class="lineNoCov">          0 :         assert(input_blob-&gt;count() == input_size);</span>
<span class="lineNum">     954 </span><span class="lineNoCov">          0 :         out_x.resize(input_size);</span>
<span class="lineNum">     955 </span>            : 
<span class="lineNum">     956 </span><span class="lineNoCov">          0 :         for (int i = 0; i &lt; input_size; ++i)</span>
<span class="lineNum">     957 </span>            :         {
<span class="lineNum">     958 </span><span class="lineNoCov">          0 :                 out_x[i] = blob_data[i];</span>
<span class="lineNum">     959 </span>            :         }
<span class="lineNum">     960 </span>            : 
<span class="lineNum">     961 </span><span class="lineNoCov">          0 :         UnnormalizeInput(out_x);</span>
<a name="962"><span class="lineNum">     962 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     963 </span>            : 
<span class="lineNum">     964 </span><span class="lineNoCov">          0 : void cNeuralNet::NormalizeInput(Eigen::MatrixXd&amp; X) const</span>
<span class="lineNum">     965 </span>            : {
<span class="lineNum">     966 </span><span class="lineNoCov">          0 :         if (ValidOffsetScale())</span>
<span class="lineNum">     967 </span>            :         {
<span class="lineNum">     968 </span><span class="lineNoCov">          0 :                 for (int i = 0; i &lt; X.rows(); ++i)</span>
<span class="lineNum">     969 </span>            :                 {
<span class="lineNum">     970 </span><span class="lineNoCov">          0 :                         auto curr_row = X.row(i);</span>
<span class="lineNum">     971 </span><span class="lineNoCov">          0 :                         curr_row += mInputOffset;</span>
<span class="lineNum">     972 </span><span class="lineNoCov">          0 :                         curr_row = curr_row.cwiseProduct(mInputScale);</span>
<span class="lineNum">     973 </span>            :                 }
<span class="lineNum">     974 </span>            :         }
<a name="975"><span class="lineNum">     975 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     976 </span>            : 
<span class="lineNum">     977 </span><span class="lineNoCov">          0 : void cNeuralNet::NormalizeInput(Eigen::VectorXd&amp; x) const</span>
<span class="lineNum">     978 </span>            : {
<span class="lineNum">     979 </span><span class="lineNoCov">          0 :         if (ValidOffsetScale())</span>
<span class="lineNum">     980 </span>            :         {
<span class="lineNum">     981 </span><span class="lineNoCov">          0 :                 assert(x.size() == mInputOffset.size());</span>
<span class="lineNum">     982 </span><span class="lineNoCov">          0 :                 assert(x.size() == mInputScale.size());</span>
<span class="lineNum">     983 </span><span class="lineNoCov">          0 :                 x += mInputOffset;</span>
<span class="lineNum">     984 </span><span class="lineNoCov">          0 :                 x = x.cwiseProduct(mInputScale);</span>
<span class="lineNum">     985 </span>            :         }
<a name="986"><span class="lineNum">     986 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     987 </span>            : 
<span class="lineNum">     988 </span><span class="lineNoCov">          0 : void cNeuralNet::NormalizeInputDiff(Eigen::VectorXd&amp; x_diff) const</span>
<span class="lineNum">     989 </span>            : {
<span class="lineNum">     990 </span><span class="lineNoCov">          0 :         if (ValidOffsetScale())</span>
<span class="lineNum">     991 </span>            :         {
<span class="lineNum">     992 </span><span class="lineNoCov">          0 :                 assert(x_diff.size() == mInputScale.size());</span>
<span class="lineNum">     993 </span><span class="lineNoCov">          0 :                 x_diff = x_diff.cwiseProduct(mInputScale);</span>
<span class="lineNum">     994 </span>            :         }
<a name="995"><span class="lineNum">     995 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">     996 </span>            : 
<span class="lineNum">     997 </span><span class="lineNoCov">          0 : void cNeuralNet::UnnormalizeInput(Eigen::VectorXd&amp; x) const</span>
<span class="lineNum">     998 </span>            : {
<span class="lineNum">     999 </span><span class="lineNoCov">          0 :         if (ValidOffsetScale())</span>
<span class="lineNum">    1000 </span>            :         {
<span class="lineNum">    1001 </span><span class="lineNoCov">          0 :                 assert(x.size() == mInputScale.size());</span>
<span class="lineNum">    1002 </span><span class="lineNoCov">          0 :                 x = x.cwiseQuotient(mInputScale);</span>
<span class="lineNum">    1003 </span><span class="lineNoCov">          0 :                 x -= mInputOffset;</span>
<span class="lineNum">    1004 </span>            :         }
<a name="1005"><span class="lineNum">    1005 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">    1006 </span>            : 
<span class="lineNum">    1007 </span><span class="lineNoCov">          0 : void cNeuralNet::UnnormalizeInputDiff(Eigen::VectorXd&amp; x_diff) const</span>
<span class="lineNum">    1008 </span>            : {
<span class="lineNum">    1009 </span><span class="lineNoCov">          0 :         if (ValidOffsetScale())</span>
<span class="lineNum">    1010 </span>            :         {
<span class="lineNum">    1011 </span><span class="lineNoCov">          0 :                 assert(x_diff.size() == mInputScale.size());</span>
<span class="lineNum">    1012 </span><span class="lineNoCov">          0 :                 x_diff = x_diff.cwiseQuotient(mInputScale);</span>
<span class="lineNum">    1013 </span>            :         }
<a name="1014"><span class="lineNum">    1014 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">    1015 </span>            : 
<span class="lineNum">    1016 </span><span class="lineNoCov">          0 : void cNeuralNet::NormalizeOutput(Eigen::VectorXd&amp; y) const</span>
<span class="lineNum">    1017 </span>            : {
<span class="lineNum">    1018 </span><span class="lineNoCov">          0 :         if (ValidOffsetScale())</span>
<span class="lineNum">    1019 </span>            :         {
<span class="lineNum">    1020 </span><span class="lineNoCov">          0 :                 assert(y.size() == mOutputOffset.size());</span>
<span class="lineNum">    1021 </span><span class="lineNoCov">          0 :                 assert(y.size() == mOutputScale.size());</span>
<span class="lineNum">    1022 </span><span class="lineNoCov">          0 :                 y += mOutputOffset;</span>
<span class="lineNum">    1023 </span><span class="lineNoCov">          0 :                 y = y.cwiseProduct(mOutputScale);</span>
<span class="lineNum">    1024 </span>            :         }
<a name="1025"><span class="lineNum">    1025 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">    1026 </span>            : 
<span class="lineNum">    1027 </span><span class="lineNoCov">          0 : void cNeuralNet::UnnormalizeOutput(Eigen::VectorXd&amp; y) const</span>
<span class="lineNum">    1028 </span>            : {
<span class="lineNum">    1029 </span><span class="lineNoCov">          0 :         if (ValidOffsetScale())</span>
<span class="lineNum">    1030 </span>            :         {
<span class="lineNum">    1031 </span><span class="lineNoCov">          0 :                 assert(y.size() == mOutputOffset.size());</span>
<span class="lineNum">    1032 </span><span class="lineNoCov">          0 :                 assert(y.size() == mOutputScale.size());</span>
<span class="lineNum">    1033 </span><span class="lineNoCov">          0 :                 y = y.cwiseQuotient(mOutputScale);</span>
<span class="lineNum">    1034 </span><span class="lineNoCov">          0 :                 y -= mOutputOffset;</span>
<span class="lineNum">    1035 </span>            :         }
<a name="1036"><span class="lineNum">    1036 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">    1037 </span>            : 
<span class="lineNum">    1038 </span><span class="lineNoCov">          0 : void cNeuralNet::NormalizeOutputDiff(Eigen::VectorXd&amp; y_diff) const</span>
<span class="lineNum">    1039 </span>            : {
<span class="lineNum">    1040 </span><span class="lineNoCov">          0 :         if (ValidOffsetScale())</span>
<span class="lineNum">    1041 </span>            :         {
<span class="lineNum">    1042 </span><span class="lineNoCov">          0 :                 assert(y_diff.size() == mOutputScale.size());</span>
<span class="lineNum">    1043 </span><span class="lineNoCov">          0 :                 y_diff = y_diff.cwiseProduct(mOutputScale);</span>
<span class="lineNum">    1044 </span>            :         }
<a name="1045"><span class="lineNum">    1045 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">    1046 </span>            : 
<span class="lineNum">    1047 </span><span class="lineNoCov">          0 : void cNeuralNet::UnnormalizeOutputDiff(Eigen::VectorXd&amp; y_diff) const</span>
<span class="lineNum">    1048 </span>            : {
<span class="lineNum">    1049 </span><span class="lineNoCov">          0 :         if (ValidOffsetScale())</span>
<span class="lineNum">    1050 </span>            :         {
<span class="lineNum">    1051 </span><span class="lineNoCov">          0 :                 assert(y_diff.size() == mOutputScale.size());</span>
<span class="lineNum">    1052 </span><span class="lineNoCov">          0 :                 y_diff = y_diff.cwiseQuotient(mOutputScale);</span>
<span class="lineNum">    1053 </span>            :         }
<a name="1054"><span class="lineNum">    1054 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">    1055 </span>            : 
<span class="lineNum">    1056 </span><span class="lineNoCov">          0 : boost::shared_ptr&lt;caffe::Net&lt;cNeuralNet::tNNData&gt;&gt; cNeuralNet::GetTrainNet() const</span>
<span class="lineNum">    1057 </span>            : {
<span class="lineNum">    1058 </span><span class="lineNoCov">          0 :         if (HasSolver())</span>
<span class="lineNum">    1059 </span>            :         {
<span class="lineNum">    1060 </span><span class="lineNoCov">          0 :                 return mSolver-&gt;GetNet();</span>
<span class="lineNum">    1061 </span>            :         }
<span class="lineNum">    1062 </span><span class="lineNoCov">          0 :         return nullptr;</span>
<a name="1063"><span class="lineNum">    1063 </span>            : }</a>
<span class="lineNum">    1064 </span>            : 
<span class="lineNum">    1065 </span><span class="lineNoCov">          0 : boost::shared_ptr&lt;caffe::MemoryDataLayer&lt;cNeuralNet::tNNData&gt;&gt; cNeuralNet::GetTrainDataLayer() const</span>
<span class="lineNum">    1066 </span>            : {
<span class="lineNum">    1067 </span><span class="lineNoCov">          0 :         if (HasSolver())</span>
<span class="lineNum">    1068 </span>            :         {
<span class="lineNum">    1069 </span><span class="lineNoCov">          0 :                 auto train_net = GetTrainNet();</span>
<span class="lineNum">    1070 </span><span class="lineNoCov">          0 :                 const std::string&amp; data_layer_name = GetInputLayerName();</span>
<span class="lineNum">    1071 </span><span class="lineNoCov">          0 :                 auto data_layer = boost::static_pointer_cast&lt;caffe::MemoryDataLayer&lt;tNNData&gt;&gt;(train_net-&gt;layer_by_name(data_layer_name));</span>
<span class="lineNum">    1072 </span><span class="lineNoCov">          0 :                 return data_layer;</span>
<span class="lineNum">    1073 </span>            :         }
<span class="lineNum">    1074 </span><span class="lineNoCov">          0 :         return nullptr;</span>
<a name="1075"><span class="lineNum">    1075 </span>            : }</a>
<span class="lineNum">    1076 </span>            : 
<span class="lineNum">    1077 </span><span class="lineNoCov">          0 : void cNeuralNet::LoadTrainData(const Eigen::MatrixXd&amp; X, const Eigen::MatrixXd&amp; Y)</span>
<span class="lineNum">    1078 </span>            : {
<span class="lineNum">    1079 </span><span class="lineNoCov">          0 :         boost::shared_ptr&lt;caffe::Net&lt;tNNData&gt;&gt; train_net = GetTrainNet();</span>
<span class="lineNum">    1080 </span><span class="lineNoCov">          0 :         auto data_layer = GetTrainDataLayer();</span>
<span class="lineNum">    1081 </span><span class="lineNoCov">          0 :         int batch_size = GetBatchSize();</span>
<span class="lineNum">    1082 </span>            : 
<span class="lineNum">    1083 </span><span class="lineNoCov">          0 :         int num_batches = static_cast&lt;int&gt;(X.rows()) / batch_size;</span>
<span class="lineNum">    1084 </span><span class="lineNoCov">          0 :         assert(num_batches == 1);</span>
<span class="lineNum">    1085 </span><span class="lineNoCov">          0 :         num_batches = 1;</span>
<span class="lineNum">    1086 </span>            : 
<span class="lineNum">    1087 </span><span class="lineNoCov">          0 :         int num_data = num_batches * batch_size;</span>
<span class="lineNum">    1088 </span><span class="lineNoCov">          0 :         int data_dim = static_cast&lt;int&gt;(X.cols());</span>
<span class="lineNum">    1089 </span><span class="lineNoCov">          0 :         int label_dim = static_cast&lt;int&gt;(Y.cols());</span>
<span class="lineNum">    1090 </span>            : 
<span class="lineNum">    1091 </span><span class="lineNoCov">          0 :         std::vector&lt;tNNData&gt; data(num_data * data_dim);</span>
<span class="lineNum">    1092 </span><span class="lineNoCov">          0 :         std::vector&lt;tNNData&gt; labels(num_data * label_dim);</span>
<span class="lineNum">    1093 </span>            : 
<span class="lineNum">    1094 </span><span class="lineNoCov">          0 :         for (int i = 0; i &lt; num_data; ++i)</span>
<span class="lineNum">    1095 </span>            :         {
<span class="lineNum">    1096 </span><span class="lineNoCov">          0 :                 auto curr_data = X.row(i);</span>
<span class="lineNum">    1097 </span><span class="lineNoCov">          0 :                 auto curr_label = Y.row(i);</span>
<span class="lineNum">    1098 </span>            : 
<span class="lineNum">    1099 </span><span class="lineNoCov">          0 :                 for (int j = 0; j &lt; data_dim; ++j)</span>
<span class="lineNum">    1100 </span>            :                 {
<span class="lineNum">    1101 </span><span class="lineNoCov">          0 :                         double val = curr_data[j];</span>
<span class="lineNum">    1102 </span><span class="lineNoCov">          0 :                         if (ValidOffsetScale())</span>
<span class="lineNum">    1103 </span>            :                         {
<span class="lineNum">    1104 </span><span class="lineNoCov">          0 :                                 val += mInputOffset[j];</span>
<span class="lineNum">    1105 </span><span class="lineNoCov">          0 :                                 val = val * mInputScale[j];</span>
<span class="lineNum">    1106 </span>            :                         }
<span class="lineNum">    1107 </span><span class="lineNoCov">          0 :                         data[i * data_dim + j] = val;</span>
<span class="lineNum">    1108 </span>            :                 }
<span class="lineNum">    1109 </span>            : 
<span class="lineNum">    1110 </span><span class="lineNoCov">          0 :                 for (int j = 0; j &lt; label_dim; ++j)</span>
<span class="lineNum">    1111 </span>            :                 {
<span class="lineNum">    1112 </span><span class="lineNoCov">          0 :                         double val = curr_label[j];</span>
<span class="lineNum">    1113 </span><span class="lineNoCov">          0 :                         if (ValidOffsetScale())</span>
<span class="lineNum">    1114 </span>            :                         {
<span class="lineNum">    1115 </span><span class="lineNoCov">          0 :                                 val += mOutputOffset[j];</span>
<span class="lineNum">    1116 </span><span class="lineNoCov">          0 :                                 val = val * mOutputScale[j];</span>
<span class="lineNum">    1117 </span>            :                         }
<span class="lineNum">    1118 </span><span class="lineNoCov">          0 :                         labels[i * label_dim + j] = val;</span>
<span class="lineNum">    1119 </span>            :                 }
<span class="lineNum">    1120 </span>            :         }
<span class="lineNum">    1121 </span>            : 
<span class="lineNum">    1122 </span><span class="lineNoCov">          0 :         data_layer-&gt;AddData(data, labels);</span>
<a name="1123"><span class="lineNum">    1123 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">    1124 </span>            : 
<span class="lineNum">    1125 </span><span class="lineNoCov">          0 : bool cNeuralNet::WriteData(const Eigen::MatrixXd&amp; X, const Eigen::MatrixXd&amp; Y, const std::string&amp; out_file)</span>
<span class="lineNum">    1126 </span>            : {
<span class="lineNum">    1127 </span><span class="lineNoCov">          0 :         bool succ = true;</span>
<span class="lineNum">    1128 </span><span class="lineNoCov">          0 :         int num_data = static_cast&lt;int&gt;(X.rows());</span>
<span class="lineNum">    1129 </span><span class="lineNoCov">          0 :         assert(num_data = static_cast&lt;int&gt;(Y.rows()));</span>
<span class="lineNum">    1130 </span><span class="lineNoCov">          0 :         int x_size = static_cast&lt;int&gt;(X.cols());</span>
<span class="lineNum">    1131 </span><span class="lineNoCov">          0 :         int y_size = static_cast&lt;int&gt;(Y.cols());</span>
<span class="lineNum">    1132 </span>            : 
<span class="lineNum">    1133 </span><span class="lineNoCov">          0 :         std::vector&lt;float&gt; x_data(num_data * x_size);</span>
<span class="lineNum">    1134 </span><span class="lineNoCov">          0 :         std::vector&lt;float&gt; y_data(num_data * y_size);</span>
<span class="lineNum">    1135 </span>            : 
<span class="lineNum">    1136 </span><span class="lineNoCov">          0 :         for (int i = 0; i &lt; num_data; ++i)</span>
<span class="lineNum">    1137 </span>            :         {
<span class="lineNum">    1138 </span><span class="lineNoCov">          0 :                 const auto&amp; curr_x = X.row(i);</span>
<span class="lineNum">    1139 </span><span class="lineNoCov">          0 :                 const auto&amp; curr_y = Y.row(i);</span>
<span class="lineNum">    1140 </span>            : 
<span class="lineNum">    1141 </span><span class="lineNoCov">          0 :                 for (int j = 0; j &lt; x_size; ++j)</span>
<span class="lineNum">    1142 </span>            :                 {
<span class="lineNum">    1143 </span><span class="lineNoCov">          0 :                         x_data[i * x_size + j] = static_cast&lt;float&gt;(curr_x(j));</span>
<span class="lineNum">    1144 </span>            :                 }
<span class="lineNum">    1145 </span>            : 
<span class="lineNum">    1146 </span><span class="lineNoCov">          0 :                 for (int j = 0; j &lt; y_size; ++j)</span>
<span class="lineNum">    1147 </span>            :                 {
<span class="lineNum">    1148 </span><span class="lineNoCov">          0 :                         y_data[i * y_size + j] = static_cast&lt;float&gt;(curr_y(j));</span>
<span class="lineNum">    1149 </span>            :                 }
<span class="lineNum">    1150 </span>            :         }
<span class="lineNum">    1151 </span>            : 
<span class="lineNum">    1152 </span><span class="lineNoCov">          0 :         const int rank = 4;</span>
<span class="lineNum">    1153 </span><span class="lineNoCov">          0 :         const hsize_t x_dims[rank] = { num_data, 1, 1, x_size };</span>
<span class="lineNum">    1154 </span><span class="lineNoCov">          0 :         const hsize_t y_dims[rank] = { num_data, 1, 1, y_size };</span>
<span class="lineNum">    1155 </span>            : 
<span class="lineNum">    1156 </span><span class="lineNoCov">          0 :         hid_t file_hid = H5Fcreate(out_file.c_str(), H5F_ACC_TRUNC, H5P_DEFAULT,</span>
<span class="lineNum">    1157 </span><span class="lineNoCov">          0 :                                                                 H5P_DEFAULT);</span>
<span class="lineNum">    1158 </span><span class="lineNoCov">          0 :         herr_t status = H5LTmake_dataset_float(file_hid, &quot;data&quot;, rank, x_dims, x_data.data());</span>
<span class="lineNum">    1159 </span><span class="lineNoCov">          0 :         if (status == 0)</span>
<span class="lineNum">    1160 </span>            :         {
<span class="lineNum">    1161 </span><span class="lineNoCov">          0 :                 status = H5LTmake_dataset_float(file_hid, &quot;label&quot;, rank, y_dims, y_data.data());</span>
<span class="lineNum">    1162 </span>            :         }
<span class="lineNum">    1163 </span>            : 
<span class="lineNum">    1164 </span><span class="lineNoCov">          0 :         if (status != 0)</span>
<span class="lineNum">    1165 </span>            :         {
<span class="lineNum">    1166 </span><span class="lineNoCov">          0 :                 succ = false;</span>
<span class="lineNum">    1167 </span>            :         }
<span class="lineNum">    1168 </span>            : 
<span class="lineNum">    1169 </span><span class="lineNoCov">          0 :         status = H5Fclose(file_hid);</span>
<span class="lineNum">    1170 </span><span class="lineNoCov">          0 :         succ &amp;= (status == 0);</span>
<span class="lineNum">    1171 </span><span class="lineNoCov">          0 :         return succ;</span>
<a name="1172"><span class="lineNum">    1172 </span>            : }</a>
<span class="lineNum">    1173 </span>            : 
<span class="lineNum">    1174 </span><span class="lineNoCov">          0 : std::string cNeuralNet::GetOffsetScaleFile(const std::string&amp; model_file) const</span>
<span class="lineNum">    1175 </span>            : {
<span class="lineNum">    1176 </span><span class="lineNoCov">          0 :         std::string scale_file = model_file;</span>
<span class="lineNum">    1177 </span><span class="lineNoCov">          0 :         scale_file = cFileUtil::RemoveExtension(scale_file);</span>
<span class="lineNum">    1178 </span><span class="lineNoCov">          0 :         scale_file += &quot;_scale.txt&quot;;</span>
<span class="lineNum">    1179 </span><span class="lineNoCov">          0 :         return scale_file;</span>
<a name="1180"><span class="lineNum">    1180 </span>            : }</a>
<span class="lineNum">    1181 </span>            : 
<span class="lineNum">    1182 </span><span class="lineNoCov">          0 : void cNeuralNet::WriteOffsetScale(const std::string&amp; norm_file) const</span>
<span class="lineNum">    1183 </span>            : {
<span class="lineNum">    1184 </span><span class="lineNoCov">          0 :         FILE* f = cFileUtil::OpenFile(norm_file, &quot;w&quot;);</span>
<span class="lineNum">    1185 </span>            : 
<span class="lineNum">    1186 </span><span class="lineNoCov">          0 :         if (f != nullptr)</span>
<span class="lineNum">    1187 </span>            :         {
<span class="lineNum">    1188 </span><span class="lineNoCov">          0 :                 std::string input_offset_json = cJsonUtil::BuildVectorJson(mInputOffset);</span>
<span class="lineNum">    1189 </span><span class="lineNoCov">          0 :                 std::string input_scale_json = cJsonUtil::BuildVectorJson(mInputScale);</span>
<span class="lineNum">    1190 </span><span class="lineNoCov">          0 :                 std::string output_offset_json = cJsonUtil::BuildVectorJson(mOutputOffset);</span>
<span class="lineNum">    1191 </span><span class="lineNoCov">          0 :                 std::string output_scale_json = cJsonUtil::BuildVectorJson(mOutputScale);</span>
<span class="lineNum">    1192 </span>            : 
<span class="lineNum">    1193 </span><span class="lineNoCov">          0 :                 fprintf(f, &quot;{\n\&quot;%s\&quot;: %s,\n\&quot;%s\&quot;: %s,\n\&quot;%s\&quot;: %s,\n\&quot;%s\&quot;: %s\n}&quot;, </span>
<span class="lineNum">    1194 </span>            :                         gInputOffsetKey.c_str(), input_offset_json.c_str(),
<span class="lineNum">    1195 </span>            :                         gInputScaleKey.c_str(), input_scale_json.c_str(),
<span class="lineNum">    1196 </span>            :                         gOutputOffsetKey.c_str(), output_offset_json.c_str(),
<span class="lineNum">    1197 </span><span class="lineNoCov">          0 :                         gOutputScaleKey.c_str(), output_scale_json.c_str());</span>
<span class="lineNum">    1198 </span>            : 
<span class="lineNum">    1199 </span><span class="lineNoCov">          0 :                 cFileUtil::CloseFile(f);</span>
<span class="lineNum">    1200 </span>            :         }
<span class="lineNum">    1201 </span>            :         else
<span class="lineNum">    1202 </span>            :         {
<span class="lineNum">    1203 </span><span class="lineNoCov">          0 :                 printf(&quot;Failed to write offset and scale to %s\n&quot;, norm_file.c_str());</span>
<span class="lineNum">    1204 </span>            :         }
<a name="1205"><span class="lineNum">    1205 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">    1206 </span>            : 
<span class="lineNum">    1207 </span><span class="lineNoCov">          0 : const std::string&amp; cNeuralNet::GetInputLayerName() const</span>
<span class="lineNum">    1208 </span>            : {
<span class="lineNum">    1209 </span><span class="lineNoCov">          0 :         return gInputLayerName;</span>
<a name="1210"><span class="lineNum">    1210 </span>            : }</a>
<span class="lineNum">    1211 </span>            : 
<span class="lineNum">    1212 </span><span class="lineNoCov">          0 : const std::string&amp; cNeuralNet::GetOutputLayerName() const</span>
<span class="lineNum">    1213 </span>            : {
<span class="lineNum">    1214 </span><span class="lineNoCov">          0 :         return gOutputLayerName;</span>
<span class="lineNum">    1215 </span>            : }
<span class="lineNum">    1216 </span>            : 
<span class="lineNum">    1217 </span>            : 
<span class="lineNum">    1218 </span>            : /////////////////////////////
<span class="lineNum">    1219 </span>            : // Caffe Net Wrapper
<a name="1220"><span class="lineNum">    1220 </span>            : /////////////////////////////</a>
<span class="lineNum">    1221 </span>            : 
<span class="lineNum">    1222 </span><span class="lineNoCov">          0 : cNeuralNet::cCaffeNetWrapper::cCaffeNetWrapper(const std::string&amp; net_file, caffe::Phase phase)</span>
<span class="lineNum">    1223 </span><span class="lineNoCov">          0 :         : caffe::Net&lt;tNNData&gt;(net_file, phase)</span>
<span class="lineNum">    1224 </span>            : {
<a name="1225"><span class="lineNum">    1225 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">    1226 </span>            : 
<span class="lineNum">    1227 </span><span class="lineNoCov">          0 : cNeuralNet::cCaffeNetWrapper::~cCaffeNetWrapper()</span>
<span class="lineNum">    1228 </span>            : {
<a name="1229"><span class="lineNum">    1229 </span><span class="lineNoCov">          0 : }</span></a>
<span class="lineNum">    1230 </span>            : 
<span class="lineNum">    1231 </span><span class="lineNoCov">          0 : int cNeuralNet::cCaffeNetWrapper::GetLayerIdx(const std::string&amp; layer_name) const</span>
<span class="lineNum">    1232 </span>            : {
<a name="1233"><span class="lineNum">    1233 </span><span class="lineNoCov">          0 :         int idx = layer_names_index_.find(layer_name)-&gt;second;</span></a>
<span class="lineNum">    1234 </span><span class="lineNoCov">          0 :         return idx;</span>
<span class="lineNum">    1235 </span><span class="lineCov">          3 : }</span>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.12</a></td></tr>
  </table>
  <br>

</body>
</html>
